{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "syllable-rnn-generation-2020-en.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iVsYe7S5XM5G"
      },
      "source": [
        "![](https://i.imgur.com/eBRPvWB.png)\n",
        "\n",
        "# Generowanie poezji za pomocą RNN i PyTorch sylabami\n",
        "\n",
        "[W tutorialu na rozgrzewkę](https://github.com/spro/practical-pytorch/blob/master/char-rnn-classification/char-rnn-classification.ipynb) użyliśmy RNN, aby sklasyfikować nazwiska znak po znaku. Tym razem wygenerujemy tekst sylaba po sylabie.\n",
        "```\n",
        "Litwo! Ojczyzno moja! ty jesteś klucz wyziemu, \n",
        "To opugo cząciły tak lasu czeleta. \n",
        "Choć nie będzie mowę świeci się za tém, \n",
        "A Dozgon++ na Litwę przerzucił w okolicy, \n",
        "Dosyć się opicie przyciągnąć w pałacu; \n",
        "\n",
        "Tamdzini nawet mimo osobnych ogórki. \n",
        "Choć zwyciętunia, mimo pukle wyślą, \n",
        "Odemknął, wbiegł wyszedł, pewnie miłośnik łowił. \n",
        "Bo przekorza, i skrobiąc nabój do Warszawy. \n",
        "Dość co oddało plecie tak fawował, \n",
        "A tam się cukier wytaczać na nich wybująca. \n",
        "\n",
        "```\n",
        "\n",
        "Ok, możesz zadać sobie pytanie, czy ten tutorial jest rzeczywiście praktyczny? Czemu nie? Modele generatywne tego typu stanowią fundament tłumaczenia maszynowego, opisywania obrazów, generowania odpowiedzi na pytania i wielu innych zastowań.\n",
        "\n",
        "Zobacz [Sequence to Sequence Translation tutorial](https://github.com/spro/practical-pytorch/blob/master/seq2seq-translation/seq2seq-translation.ipynb) żeby nauczyć się więcej w tym temacie."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WamMk47AXM5I"
      },
      "source": [
        "## Polecana lektura\n",
        "\n",
        "Zakładam, że jest już zainstalowany PyTorch, znasz Python'a, oraz znasz pojęcie Tensor'ów:\n",
        "\n",
        "* http://pytorch.org/ - instalacja PyTorch\n",
        "* [Deep Learning with PyTorch: A 60-minute Blitz](http://pytorch.org/tutorials/beginner/deep_learning_60min_blitz.html) - Podstawy PyTorch\n",
        "* [jcjohnson's PyTorch examples](https://github.com/jcjohnson/pytorch-examples) przykłady wykorzystania PyTorch\n",
        "* [Introduction to PyTorch for former Torchies](https://github.com/pytorch/tutorials/blob/master/Introduction%20to%20PyTorch%20for%20former%20Torchies.ipynb) jeżeli znasz Lua Torch\n",
        "\n",
        "Trochę wiedzy o RNN:\n",
        "\n",
        "* [The Unreasonable Effectiveness of Recurrent Neural Networks](http://karpathy.github.io/2015/05/21/rnn-effectiveness/) przykłady z życia wzięte\n",
        "* [Understanding LSTM Networks](http://colah.github.io/posts/2015-08-Understanding-LSTMs/) RNN i LSTM w pigułce\n",
        "\n",
        "Zobacz także podobne tutoriale z serii:\n",
        "\n",
        "* [Classifying Names with a Character-Level RNN](https://github.com/spro/practical-pytorch/blob/master/char-rnn-classification/char-rnn-classification.ipynb) używa RNN do klasyfikacji\n",
        "* [Generating Names with a Conditional Character-Level RNN](https://github.com/spro/practical-pytorch/blob/master/conditional-char-rnn/conditional-char-rnn.ipynb) opierając się na tym modelu, dodaje kategorię jako dane wejściowe"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E7PwzxO-hBJe"
      },
      "source": [
        "## Setup"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MVR_A2s-jjiD"
      },
      "source": [
        "## Instalacja biblioteki PyDrive i wrappera"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WShJMdkejkV_"
      },
      "source": [
        "# This only needs to be done once per notebook.\n",
        "!pip install -U -q PyDrive\n",
        "\n",
        "from pydrive.auth import GoogleAuth\n",
        "from pydrive.drive import GoogleDrive\n",
        "from google.colab import auth\n",
        "from oauth2client.client import GoogleCredentials\n",
        "\n",
        "# Authenticate and create the PyDrive client.\n",
        "# This only needs to be done once per notebook.\n",
        "auth.authenticate_user()\n",
        "gauth = GoogleAuth()\n",
        "gauth.credentials = GoogleCredentials.get_application_default()\n",
        "drive = GoogleDrive(gauth)\n",
        "\n",
        "from pathlib import Path\n",
        "import os\n",
        "\n",
        "def download_and_save(file_name, file_id):\n",
        "  downloaded = drive.CreateFile({'id': file_id})\n",
        "  # fetch file\n",
        "  downloaded.FetchContent()\n",
        "  # write file\n",
        "  with open(file_name,'wb') as f:\n",
        "       f.write(downloaded.content.read())\n",
        "      \n",
        "  print(f'Saved {file_name}')\n",
        "  \n",
        "FILE_NAME, FILE_ID = ['file_name', 'file_id']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mzZIXB-0zkmK"
      },
      "source": [
        "## Pobranie i instalacja stemmera"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qEmB620tjBKi",
        "outputId": "33df70e4-bf80-4dc5-cb84-387c13dad5c7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "!dpkg --add-architecture i386\n",
        "!apt-get -qq update\n",
        "!apt-get -qq install libc6:i386 libncurses5:i386 libstdc++6:i386"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Preconfiguring packages ...\n",
            "Selecting previously unselected package gcc-8-base:i386.\n",
            "(Reading database ... 144786 files and directories currently installed.)\n",
            "Preparing to unpack .../0-gcc-8-base_8.4.0-1ubuntu1~18.04_i386.deb ...\n",
            "Unpacking gcc-8-base:i386 (8.4.0-1ubuntu1~18.04) ...\n",
            "Selecting previously unselected package libgcc1:i386.\n",
            "Preparing to unpack .../1-libgcc1_1%3a8.4.0-1ubuntu1~18.04_i386.deb ...\n",
            "Unpacking libgcc1:i386 (1:8.4.0-1ubuntu1~18.04) ...\n",
            "Selecting previously unselected package libc6:i386.\n",
            "Preparing to unpack .../2-libc6_2.27-3ubuntu1.3_i386.deb ...\n",
            "Unpacking libc6:i386 (2.27-3ubuntu1.3) ...\n",
            "Replacing files in old package libc6-i386 (2.27-3ubuntu1.3) ...\n",
            "Selecting previously unselected package libtinfo5:i386.\n",
            "Preparing to unpack .../3-libtinfo5_6.1-1ubuntu1.18.04_i386.deb ...\n",
            "Unpacking libtinfo5:i386 (6.1-1ubuntu1.18.04) ...\n",
            "Selecting previously unselected package libncurses5:i386.\n",
            "Preparing to unpack .../4-libncurses5_6.1-1ubuntu1.18.04_i386.deb ...\n",
            "Unpacking libncurses5:i386 (6.1-1ubuntu1.18.04) ...\n",
            "Selecting previously unselected package libstdc++6:i386.\n",
            "Preparing to unpack .../5-libstdc++6_8.4.0-1ubuntu1~18.04_i386.deb ...\n",
            "Unpacking libstdc++6:i386 (8.4.0-1ubuntu1~18.04) ...\n",
            "Selecting previously unselected package libgpm2:i386.\n",
            "Preparing to unpack .../6-libgpm2_1.20.7-5_i386.deb ...\n",
            "Unpacking libgpm2:i386 (1.20.7-5) ...\n",
            "Setting up gcc-8-base:i386 (8.4.0-1ubuntu1~18.04) ...\n",
            "Setting up libc6:i386 (2.27-3ubuntu1.3) ...\n",
            "Setting up libgcc1:i386 (1:8.4.0-1ubuntu1~18.04) ...\n",
            "Setting up libtinfo5:i386 (6.1-1ubuntu1.18.04) ...\n",
            "Setting up libgpm2:i386 (1.20.7-5) ...\n",
            "Setting up libstdc++6:i386 (8.4.0-1ubuntu1~18.04) ...\n",
            "Setting up libncurses5:i386 (6.1-1ubuntu1.18.04) ...\n",
            "Processing triggers for libc-bin (2.27-3ubuntu1.2) ...\n",
            "/sbin/ldconfig.real: /usr/local/lib/python3.6/dist-packages/ideep4py/lib/libmkldnn.so.0 is not a symbolic link\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hlv4wsejjSOe",
        "outputId": "19c33524-7283-447b-ab3d-5d8613718cb6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# stemmer-2.0.3.tgz, https://drive.google.com/file/d/1PxS-e6tzXa7u4N9A2r9XWLUpvSKqJIrZ\n",
        "stemmer = {FILE_NAME: 'stemmer-2.0.3.tgz', FILE_ID: '1PxS-e6tzXa7u4N9A2r9XWLUpvSKqJIrZ'}\n",
        "stemmer_path = Path('./') / stemmer[FILE_NAME]\n",
        "download_and_save(stemmer_path, stemmer[FILE_ID])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Saved stemmer-2.0.3.tgz\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oitYYaiVjSRT"
      },
      "source": [
        "!tar xzf $stemmer_path"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iGEJUx4GkFUU",
        "outputId": "ca3c748c-d89b-4659-d86d-8f0f3eb35aab",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "ls -lah bin"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "total 8.2M\n",
            "drwxr-xr-x 2  501 staff 4.0K Apr 30  2018 \u001b[0m\u001b[01;34m.\u001b[0m/\n",
            "drwxr-xr-x 1 root root  4.0K Nov 14 11:42 \u001b[01;34m..\u001b[0m/\n",
            "-rw-r--r-- 1  501 staff 1.2K Apr 19  2018 changelog.txt\n",
            "-rwxr-xr-x 1  501 staff  629 Jan  2  2018 \u001b[01;32mdestem.sh\u001b[0m*\n",
            "-rw-r--r-- 1  501 staff 858K Nov 22  2017 stemmer2.dic\n",
            "-rwxrwxr-x 1  501 staff 3.7M Apr 19  2018 \u001b[01;32mstemmer.linux\u001b[0m*\n",
            "-rwxr-xr-x 1  501 staff 3.6M Apr 30  2018 \u001b[01;32mstemmer.macos\u001b[0m*\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6a-q1f8LFI5y"
      },
      "source": [
        "# Pobranie danych"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p_CBUv1zksmM",
        "outputId": "cf8e83fb-8874-4ce6-8da2-6e22ac42da91",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "from pathlib import Path\n",
        "dataset_path =   Path('data/rnn_generator'); dataset_path\n",
        "!mkdir -p $dataset_path\n",
        "!ls -la $dataset_path/\n",
        "tmp_path = dataset_path / 'tmp/'\n",
        "!mkdir -p $tmp_path"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "total 8\n",
            "drwxr-xr-x 2 root root 4096 Nov 14 11:45 .\n",
            "drwxr-xr-x 3 root root 4096 Nov 14 11:45 ..\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4q8kPT9ql7pa"
      },
      "source": [
        "## Pobranie datasetu Pan Tadeusz"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OUn5JvPtl9zN",
        "outputId": "60527078-0419-4ec1-9798-7f3ab848ee87",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# pan_tadeusz, https://drive.google.com/open?id=1l8KGrqUsrGOlXVp7Frgyku8w75X_WA8h\n",
        "pan_tadeusz = {FILE_NAME: 'pan_tadeusz.txt', FILE_ID: '1l8KGrqUsrGOlXVp7Frgyku8w75X_WA8h'}\n",
        "\n",
        "download_and_save(dataset_path / pan_tadeusz[FILE_NAME], pan_tadeusz[FILE_ID])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Saved data/rnn_generator/pan_tadeusz.txt\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rMHb4Kjyl_3m",
        "outputId": "67939356-3097-439e-eb3d-d3c07248b27c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "ls -la $dataset_path/"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "total 232\n",
            "drwxr-xr-x 3 root root   4096 Nov 14 11:50 \u001b[0m\u001b[01;34m.\u001b[0m/\n",
            "drwxr-xr-x 3 root root   4096 Nov 14 11:45 \u001b[01;34m..\u001b[0m/\n",
            "-rw-r--r-- 1 root root 223706 Nov 14 11:50 pan_tadeusz.txt\n",
            "drwxr-xr-x 2 root root   4096 Nov 14 11:49 \u001b[01;34mtmp\u001b[0m/\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zoKLKM4tqfcI"
      },
      "source": [
        "## Opcjonalne pobranie innych datasetów"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D0FCIdSvmIuE",
        "outputId": "a0683604-2525-4501-b48d-04ebad079430",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# witkacy_szewcy, https://drive.google.com/open?id=1NOWTocYwv93GibItaNBxTJobjTukQmRP\n",
        "witkacy = {FILE_NAME: 'witkacy_szewcy.txt', FILE_ID: '1NOWTocYwv93GibItaNBxTJobjTukQmRP'}\n",
        "\n",
        "download_and_save(dataset_path / witkacy[FILE_NAME], witkacy[FILE_ID])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Saved data/rnn_generator/witkacy_szewcy.txt\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6KcOcAXTmPAl",
        "outputId": "6f9e02bd-bed3-4296-dfd7-52e7892f7387",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# mickiewicz, https://drive.google.com/open?id=1otbOB7GjKEVPjaPShaaTnYQnv-whwNWP\n",
        "mickiewicz = {FILE_NAME: 'mickiewicz.txt', FILE_ID: '1otbOB7GjKEVPjaPShaaTnYQnv-whwNWP'}\n",
        "\n",
        "download_and_save(dataset_path / mickiewicz[FILE_NAME], mickiewicz[FILE_ID])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Saved data/rnn_generator/mickiewicz.txt\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5y3kejFXmRku",
        "outputId": "82f998fd-d6fe-4548-dfd4-ec3f4bfe0b51",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "!ls -la $dataset_path/"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "total 1088\n",
            "drwxr-xr-x 3 root root   4096 Nov 14 11:52 .\n",
            "drwxr-xr-x 3 root root   4096 Nov 14 11:45 ..\n",
            "-rw-r--r-- 1 root root 725495 Nov 14 11:52 mickiewicz.txt\n",
            "-rw-r--r-- 1 root root 223706 Nov 14 11:50 pan_tadeusz.txt\n",
            "drwxr-xr-x 2 root root   4096 Nov 14 11:49 tmp\n",
            "-rw-r--r-- 1 root root 145132 Nov 14 11:51 witkacy_szewcy.txt\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tnHlimami7b1"
      },
      "source": [
        "## Załadowanie bibliotek"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1Kk5FdvHFDeu"
      },
      "source": [
        "## Instalacja biblioteki PyDrive i wrappera"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WMhhgYDig_7G"
      },
      "source": [
        "from pathlib import Path\n",
        "import platform\n",
        "import string\n",
        "import random\n",
        "import re\n",
        "from IPython.core.display import display, HTML\n",
        "import os\n",
        "import psutil\n",
        "import pickle\n",
        "import warnings\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.autograd import Variable\n",
        "import time, math\n",
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.ticker as ticker\n",
        "%matplotlib inline\n",
        "\n",
        "import matplotlib as mpl\n",
        "mpl.style.use('default')\n",
        "mpl.style.use('bmh')\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g8KbaMvrXM5J"
      },
      "source": [
        "## Preprocessing korpusu"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "80ZjgATAXsVn"
      },
      "source": [
        "dataset_path = Path('data/rnn_generator'); dataset_path\n",
        "tmp_path = dataset_path / 'tmp/'\n",
        "!mkdir -p $tmp_path"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CPFXCZguyyXA",
        "outputId": "6a7c74c3-3a29-4189-f73d-0975c83784f9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "ls -lah $dataset_path/"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "total 1.1M\n",
            "drwxr-xr-x 3 root root 4.0K Nov 14 11:52 \u001b[0m\u001b[01;34m.\u001b[0m/\n",
            "drwxr-xr-x 3 root root 4.0K Nov 14 11:45 \u001b[01;34m..\u001b[0m/\n",
            "-rw-r--r-- 1 root root 709K Nov 14 11:52 mickiewicz.txt\n",
            "-rw-r--r-- 1 root root 219K Nov 14 11:50 pan_tadeusz.txt\n",
            "drwxr-xr-x 2 root root 4.0K Nov 14 11:53 \u001b[01;34mtmp\u001b[0m/\n",
            "-rw-r--r-- 1 root root 142K Nov 14 11:51 witkacy_szewcy.txt\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9eTRgNsMyyXD"
      },
      "source": [
        "fn_corpus_char = dataset_path/'pan_tadeusz.txt'\n",
        "fn_corpus_caps = dataset_path/'pan_tadeusz.caps1.txt'\n",
        "fn_corpus_syl = dataset_path/'pan_tadeusz.syl1.txt'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9wuZu6mE057C"
      },
      "source": [
        "Plik wejściowy (korpus) to duży plik tekstowy. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aaV5Ly3R_tzj",
        "outputId": "9682c508-8fa6-4871-a707-62f3a70a8866",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "!head -n 21 $fn_corpus_char"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "﻿KSIĘGA PIÉRWSZA.\r\n",
            "\r\n",
            "\r\n",
            "\r\n",
            "\r\n",
            "GOSPODARSTWO.\r\n",
            "\r\n",
            "\r\n",
            "TREŚĆ.\r\n",
            "\r\n",
            "    Powrot panicza -- Spotkanie się piérwsze w pokoiku, drugie u\r\n",
            "    stołu -- Ważna Sędziego nauka o grzeczności -- Podkomorzego uwagi\r\n",
            "    polityczne nad modami -- Początek sporu o Kusego i Sokoła -- Żale\r\n",
            "    Wojskiego -- Ostatni Woźny Trybunału -- Rzut oka na ówczesny stan\r\n",
            "    polityczny Litwy i Europy.\r\n",
            "\r\n",
            "\r\n",
            "  Litwo! Ojczyzno moja! ty jesteś jak zdrowie;\r\n",
            "Ile cię trzeba cenić, ten tylko się dowie\r\n",
            "Kto cię stracił. Dziś piękność twą w całéj ozdobie\r\n",
            "Widzę i opisuję, bo tęsknię po tobie.\r\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IKPynzs-yyW-"
      },
      "source": [
        "### Tokenizacja wielkich liter"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "enPpQXzj_oj6"
      },
      "source": [
        "Zamieniamy duże litery na małe dodając tokeny `_up_` (dla wyrazów pisanych wielkimi literami) lub `_cap_` (dla wyrazów pisanych z wielkiej litery)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UJtiF_yZiA-z"
      },
      "source": [
        "def do_caps(ss):\n",
        "  TOK_UP,TOK_CAP = ' _up_ ', ' _cap_ '\n",
        "  res = []\n",
        "  re_word = re.compile('\\w')\n",
        "  for s in re.findall(r'\\w+|\\W+', ss):\n",
        "      res += ([TOK_UP,s.lower()] if (s.isupper() and (len(s)>2))\n",
        "              else [TOK_CAP,s.lower()] if s.istitle()\n",
        "              else [s.lower()])\n",
        "  return ''.join(res)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b5cAVEtNiC9X",
        "outputId": "f788ba2b-60dc-4468-b02a-7dacd9cf0050",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "corpus_tmp = fn_corpus_char.open('r').read()\n",
        "corpus_tmp = do_caps(corpus_tmp)\n",
        "fn_corpus_caps.open('w').write(corpus_tmp)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "246668"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JJlxNo8q-quJ",
        "outputId": "ff278190-13d3-41ad-d66a-2fdf226bf7c6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "!head -n 21 $fn_corpus_caps"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "﻿ _up_ księga  _up_ piérwsza.\n",
            "\n",
            "\n",
            "\n",
            "\n",
            " _up_ gospodarstwo.\n",
            "\n",
            "\n",
            " _up_ treść.\n",
            "\n",
            "     _cap_ powrot panicza --  _cap_ spotkanie się piérwsze w pokoiku, drugie u\n",
            "    stołu --  _cap_ ważna  _cap_ sędziego nauka o grzeczności --  _cap_ podkomorzego uwagi\n",
            "    polityczne nad modami --  _cap_ początek sporu o  _cap_ kusego i  _cap_ sokoła --  _cap_ żale\n",
            "     _cap_ wojskiego --  _cap_ ostatni  _cap_ woźny  _cap_ trybunału --  _cap_ rzut oka na ówczesny stan\n",
            "    polityczny  _cap_ litwy i  _cap_ europy.\n",
            "\n",
            "\n",
            "   _cap_ litwo!  _cap_ ojczyzno moja! ty jesteś jak zdrowie;\n",
            " _cap_ ile cię trzeba cenić, ten tylko się dowie\n",
            " _cap_ kto cię stracił.  _cap_ dziś piękność twą w całéj ozdobie\n",
            " _cap_ widzę i opisuję, bo tęsknię po tobie.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lbMBLa_nxp2b"
      },
      "source": [
        "### Podział korpusu na sylaby"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OONrdDyb-mS6"
      },
      "source": [
        "Dzielimy korpus na sylaby programem `stemmer`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "efaGn-TLyyXG"
      },
      "source": [
        "platform_suffixes = {'Linux': 'linux', 'Darwin': 'macos'}\n",
        "platform_suffix = platform_suffixes[platform.system()]\n",
        "stemmer_bin = f'LD_PRELOAD=\"\" bin/stemmer.{platform_suffix}'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w3qYJ20EyyXI"
      },
      "source": [
        "# !$stemmer_bin -h"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xGbQYAUYyyXK",
        "outputId": "a879591e-8cd4-43c9-f2fc-65b04d80fe46",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "!$stemmer_bin -s 7683 -v -d bin/stemmer2.dic -i $fn_corpus_caps -o $fn_corpus_syl"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Stemmer 2.0.3 2018-04-19 (Linux i386)\n",
            "For Korrida database, spellchecker and hyphenator copyright (C) 1993-2018 Wojciech Czarnowski\n",
            "For Stemmer copyright (C) 2018 Krzysztof Wolk and Wojciech Czarnowski\n",
            "Wojciech Czarnowski: wojtek.czarnowski@gmail.com, +48(608)202-272\n",
            "Krzysztof Wolk: krz.wolk@gmail.com, +48(606)918-623\n",
            "\n",
            "Dictionary: \"bin/stemmer2.dic\"\n",
            "Input file: \"data/rnn_generator/pan_tadeusz.caps1.txt\"\n",
            "Output file: \"data/rnn_generator/pan_tadeusz.syl1.txt\"\n",
            "Stem number: \"7683\"\n",
            "\n",
            "Stemming options:\n",
            "  StemNiePrefix     : Yes\n",
            "  StemExtraPrefixes : Yes\n",
            "  StemPrefixesInRoot: No\n",
            "\n",
            "Syllable division options:\n",
            "  DivideWords          : Yes\n",
            "  DivideWithDictionary : Yes\n",
            "  DivideAlgorithmically: Yes\n",
            "  DivideUknkownWords   : Yes\n",
            "  divideAfterChar      : 1\n",
            "\n",
            "Stemming formatting options:\n",
            "  StemInSuffix       : No\n",
            "  ShowPOSInfo        : No\n",
            "  ShowExtraPOSInfo   : No\n",
            "\n",
            "  ShowGroupCode      : No\n",
            "  ShowBaseSuffixCodes: No\n",
            "  ShowSuffixCode     : No\n",
            "\n",
            "  stemDelimiterStr   : \"++ --\"\n",
            "  codeDelimiterStr   : \"@@\"\n",
            "\n",
            "StemFile(fileInPath: \"data/rnn_generator/pan_tadeusz.caps1.txt\", fileOutPath: \"data/rnn_generator/pan_tadeusz.syl1.txt\")\n",
            "Finished.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rurUv5wf_135",
        "outputId": "706c197b-f8b8-4e54-b919-917d2def1aa9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "!head -n 21 $fn_corpus_syl"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " _up_ księ++ --ga  _up_ pié++ --rwsza.\n",
            "\n",
            "\n",
            "\n",
            "\n",
            " _up_ go++ --s++ --po++ --dar++ --stwo.\n",
            "\n",
            "\n",
            " _up_ treść.\n",
            "\n",
            "     _cap_ po++ --wrot pa++ --ni++ --cza --  _cap_ spot++ --ka++ --nie się pié++ --rwsze w po++ --koi++ --ku, dru++ --gie u\n",
            "    sto++ --łu --  _cap_ waż++ --na  _cap_ sę++ --dzie++ --go na++ --u++ --ka o grze++ --cz++ --no++ --ści --  _cap_ pod++ --ko++ --mo++ --rze++ --go u++ --wa++ --gi\n",
            "    po++ --li++ --ty++ --cz++ --ne nad mo++ --da++ --mi --  _cap_ po++ --czą++ --tek spo++ --ru o  _cap_ ku++ --se++ --go i  _cap_ so++ --ko++ --ła --  _cap_ ża++ --le\n",
            "     _cap_ woj++ --skie++ --go --  _cap_ o++ --sta++ --t++ --ni  _cap_ woź++ --ny  _cap_ try++ --bu++ --na++ --łu --  _cap_ rzut oka na ów++ --czes++ --ny stan\n",
            "    po++ --li++ --ty++ --cz++ --ny  _cap_ lit++ --wy i  _cap_ eu++ --ro++ --py.\n",
            "\n",
            "\n",
            "   _cap_ lit++ --wo!  _cap_ oj++ --czyz++ --no mo++ --ja! ty je++ --s++ --teś jak zdro++ --wie;\n",
            " _cap_ ile cię trze++ --ba ce++ --nić, ten tyl++ --ko się do++ --wie\n",
            " _cap_ kto cię stra++ --cił.  _cap_ dziś pięk++ --ność twą w całéj o++ --zdo++ --bie\n",
            " _cap_ wi++ --dzę i o++ --pi++ --su++ --ję, bo tęs++ --knię po to++ --bie.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vpf6QibJyyXL"
      },
      "source": [
        "### Załadowanie do pamięci i tokenizacja"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OSyGzgVD057R"
      },
      "source": [
        "Ładujemy korpus do pamięci i tokenizujemy. Tworzymy też listę wszystkich tokenów `all_tokens`. Mamy już specjalne tokeny `_cap_` i `_up_`, zamieniamy znaki końca lini na token `_eol_` i dodajemy token `_unk_` na wypadek, gdybyśmy użyli sylaby (tokena), który nie wystąpił wcześniej w korpusie."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g9H83p3sXM5L",
        "outputId": "a3b85538-3ce9-4c0b-d1df-2a78ec4aa7ec",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "file = open(fn_corpus_syl).read()\n",
        "file_len = len(file)\n",
        "print('file_len =', file_len)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "file_len = 398396\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "maVrQMtZyyXU",
        "outputId": "6315e8fc-6597-42c2-ebf5-cbc97761ca66",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# taken from fastai/text.py\n",
        "\n",
        "# remove +,- chars from punctuation set to keep syllables e.g.'--PO++' intact\n",
        "# remove _ char to keep tokens intact\n",
        "punctuation=re.sub('[_\\+-]', '', string.punctuation)\n",
        "re_tok = re.compile(f'([{punctuation}“”¨«»®´·º½¾¿¡§£₤‘’])')\n",
        "\n",
        "def tokenize(s, repl_unk=True): \n",
        "  strings = re_tok.sub(r' \\1 ', s).replace('\\n', ' _eol_ ').split()\n",
        "  if repl_unk:\n",
        "    strings = [str2tok(s) for s in strings]\n",
        "  return strings\n",
        "\n",
        "file_tok = tokenize(file, repl_unk=False); len(file_tok), file_tok[:8]\n",
        "file_tok_len = len(file_tok)\n",
        "\n",
        "spec_tokens = ['_unk_', '_eol_', '_cap_', '_up_']\n",
        "\n",
        "all_tokens = []\n",
        "all_tokens.extend(spec_tokens)\n",
        "all_tokens.extend(sorted(list(set(file_tok))))\n",
        "n_tokens = len(all_tokens); print(n_tokens, all_tokens[:50])\n",
        "\n",
        "tok2idx_dict = {tok: idx for (idx, tok) in enumerate(all_tokens)}\n",
        "\n",
        "def str2tok(str) -> int:\n",
        "  return str if tok2idx_dict.get(str, 0) else all_tokens[0]\n",
        "\n",
        "def tok2idx(tok) -> int:\n",
        "  return tok2idx_dict.get(tok, 0)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "5059 ['_unk_', '_eol_', '_cap_', '_up_', '!', '\"', '%', \"'\", '(', ')', ',', '--', '--a++', '--aczéj', '--ał', '--b++', '--ba', '--ba++', '--bach', '--baj++', '--bak', '--ban', '--ban++', '--bar++', '--barz', '--baw', '--baw++', '--bał', '--baż', '--bcem', '--be++', '--bek', '--bel', '--bel++', '--belg', '--bem', '--ber++', '--bez++', '--beł', '--bi', '--bi++', '--bia', '--bia++', '--biad', '--biar++', '--biać', '--biał', '--bic', '--bie', '--bie++']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zaNxdcoMADVS"
      },
      "source": [
        "Przyda nam się funkcja do zakodowania dowolnego tekstu na listę zsylabizowanych tokenów:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rDQqpRYzxT4L"
      },
      "source": [
        "def str2syl2tok(text):  \n",
        "  fn_tmp_text_caps = Path(tmp_path / 'tmp_text_caps1.txt')\n",
        "  fn_tmp_text_syl = Path(tmp_path / 'tmp_text_syl1.txt')\n",
        "  \n",
        "  text = do_caps(text)\n",
        "  fn_tmp_text_caps.open('w').write(text)\n",
        "  \n",
        "  !$stemmer_bin -s 7683 -d bin/stemmer2.dic -i $fn_tmp_text_caps -o $fn_tmp_text_syl\n",
        "  \n",
        "  text_syl = fn_tmp_text_syl.open('r').read()\n",
        "  \n",
        "  # kill last \\n eol char possibly added by stemmer\n",
        "  if text_syl[-1] == '\\n':\n",
        "    text_syl = text_syl[:-1]\n",
        "\n",
        "  text_tok = tokenize(text_syl, repl_unk=True)\n",
        "    \n",
        "  return text_tok"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gwnDdj75paVP",
        "outputId": "620b3b0b-598f-4d39-b23f-e6961a7ce0c4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "tekst = 'LITWO! Ojczyzno moja!\\nTy jesteś jak zdrowie.\\nIle cię trzeba cenić ble ble '\n",
        "tekst_tok = str2syl2tok(tekst); print(tekst_tok)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['_up_', 'lit++', '--wo', '!', '_cap_', 'oj++', '--czyz++', '--no', 'mo++', '--ja', '!', '_eol_', '_cap_', 'ty', 'je++', '--s++', '--teś', 'jak', 'zdro++', '--wie', '.', '_eol_', '_cap_', 'ile', 'cię', 'trze++', '--ba', 'ce++', '--nić', '_unk_', '_unk_']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bAUKI80V6CvK"
      },
      "source": [
        "Funkcje pomocnicze do zdekodowania listy tokenów na tekst:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JzAAi_95yyXq",
        "outputId": "5e16fc36-28bf-45e7-bc1e-9eb8ac078836",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "def syl2str(a_list, delim='/'): \n",
        "  s = ' '.join(a_list)\n",
        "  \n",
        "  repl_list = [\n",
        "      ('++ --', delim), \n",
        "  ]\n",
        "  for repl in repl_list:\n",
        "    s = s.replace(repl[0], repl[1])\n",
        "  \n",
        "  return s\n",
        "\n",
        "print(syl2str(tekst_tok))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "_up_ lit/wo ! _cap_ oj/czyz/no mo/ja ! _eol_ _cap_ ty je/s/teś jak zdro/wie . _eol_ _cap_ ile cię trze/ba ce/nić _unk_ _unk_\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pUs-bnu5q2FF",
        "outputId": "6925a5ea-5d86-4230-edd0-32004f89305c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "def decode_tokens(e_str):\n",
        "  # decode _eol_, _cap_ and _up_\n",
        "  # leave _unk_ token alone\n",
        "  e_syl = e_str.split(' ')\n",
        "  e_syl2 = []\n",
        "\n",
        "  cap = False; up = False\n",
        "\n",
        "  for syl in e_syl:\n",
        "    if syl == '_eol_': syl = '\\n'\n",
        "\n",
        "    if syl not in ['_cap_', '_up_']:\n",
        "      if cap == True: syl = syl.title(); cap = False\n",
        "      if up == True: syl = syl.upper(); up = False        \n",
        "      e_syl2.append(syl)\n",
        "\n",
        "    if syl == '_cap_': cap = True\n",
        "    if syl == '_up_': up = True\n",
        "\n",
        "  return ' '.join(e_syl2)\n",
        "\n",
        "print(decode_tokens(syl2str(tekst_tok, delim=''))[:300])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "LITWO ! Ojczyzno moja ! \n",
            " Ty jesteś jak zdrowie . \n",
            " Ile cię trzeba cenić _unk_ _unk_\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pqbQLawfrV-n",
        "outputId": "7221e3d0-56e1-4c4c-8a11-467cfd4de978",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "def fix_punctuation(s): \n",
        "  repl_list = [\n",
        "      ('\\n ', '\\n'), \n",
        "      (' ,', ','),\n",
        "      (' .', '.'),\n",
        "      (' !', '!'),\n",
        "      (' ?', '?'),\n",
        "      (' ;', ';'),\n",
        "      ('( ', '('),\n",
        "      (' )', ')'),\n",
        "      (' «', '«'),\n",
        "      ('» ', '»'),\n",
        "      (' :', ':')\n",
        "  ]\n",
        "  \n",
        "  for repl in repl_list:\n",
        "    s = s.replace(repl[0], repl[1])\n",
        "  \n",
        "  return s\n",
        "\n",
        "print(fix_punctuation(decode_tokens(syl2str(tekst_tok, delim='')))[:300])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "LITWO! Ojczyzno moja! \n",
            "Ty jesteś jak zdrowie. \n",
            "Ile cię trzeba cenić _unk_ _unk_\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v2VJHqQmCyuT"
      },
      "source": [
        "Sformatujmy zdekodowany tekst w HTML i zaznaczmy na czerwono sylaby, z których nie dało się skleić słów."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WFj5nGp5yyYI",
        "outputId": "23ea0f60-fee7-47de-cbdf-18e61f9a7866",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "class X(str):\n",
        "    def rpl(self, p, c='lightgray'):\n",
        "        return X(self.replace(p, f'<font color=\"{c}\">{p}</font>'))\n",
        "    def rpl2(self, p, p2):\n",
        "        return X(self.replace(p, p2))\n",
        "      \n",
        "def format_html(e_str):\n",
        "  return X(e_str).rpl('/').rpl('--', c='red').rpl('++', c='red').rpl2('\\n', '\\n<br/>')\n",
        "\n",
        "e_str = fix_punctuation(decode_tokens(syl2str(tekst_tok, delim='')))[:400]\n",
        "e_html = format_html(e_str); display(HTML(e_html))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "LITWO! Ojczyzno moja! \n",
              "<br/>Ty jesteś jak zdrowie. \n",
              "<br/>Ile cię trzeba cenić _unk_ _unk_"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nnmXGTva5nw-"
      },
      "source": [
        "## Przygotowanie treningu"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2cIY0S4g0gZo"
      },
      "source": [
        "### GPU?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2hTjsshick9K",
        "outputId": "8e6d4d3f-f4ee-4e7e-bc06-fb06e68f70b4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "USE_GPU = torch.cuda.is_available(); \n",
        "# USE_GPU = False; \n",
        "\n",
        "print(f'USE_GPU={USE_GPU}')\n",
        "\n",
        "def to_gpu(x, *args, **kwargs):\n",
        "    return x.cuda(*args, **kwargs) if USE_GPU else x"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "USE_GPU=True\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X5cFLx6WXM5X"
      },
      "source": [
        "### Budowa sieci rekurencyjnej\n",
        "\n",
        "Ten model przyjmie jako wejściie token dla kroku $ t _ {- 1} $ i ma wyprowadzić następny token $ t $. Istnieją trzy warstwy - jedna warstwa liniowa, która koduje znak wejściowy do stanu wewnętrznego, jedna warstwa GRU (która może sama mieć wiele warstw), która działa na tym stanie wewnętrznym i stanie ukrytym, oraz warstwa dekodera, która wyprowadza rozkład prawdopodobieństwa."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tZ8chQcVXM5X"
      },
      "source": [
        "class RNN(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size, output_size, n_layers=1):\n",
        "        super(RNN, self).__init__()\n",
        "        self.input_size = input_size\n",
        "        self.hidden_size = hidden_size\n",
        "        self.output_size = output_size\n",
        "        self.n_layers = n_layers\n",
        "        \n",
        "        self.encoder = nn.Embedding(input_size, hidden_size)\n",
        "        self.gru = nn.GRU(hidden_size, hidden_size, n_layers)\n",
        "        self.decoder = nn.Linear(hidden_size, output_size)\n",
        "    \n",
        "    def forward(self, input, hidden):\n",
        "        input = self.encoder(input.view(1, -1))\n",
        "        output, hidden = self.gru(input.view(1, 1, -1), hidden)\n",
        "        output = self.decoder(output.view(1, -1))\n",
        "        return output, hidden\n",
        "\n",
        "    def init_hidden(self):\n",
        "        return Variable(to_gpu(torch.zeros(self.n_layers, 1, self.hidden_size)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "62XSRFgkXM5Z"
      },
      "source": [
        "### Tensory wejściowe i docelowe"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lL_XOG-fXM5T"
      },
      "source": [
        "Aby stworzyć 'wejścia' z tego dużego ciągu danych, podzielimy go na kawałki po 400 sylab:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_zwmRSAHXM5T",
        "outputId": "a87903a5-72ae-4570-869c-d8d4617c652a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "chunk_len = 400\n",
        "\n",
        "def random_chunk():\n",
        "    start_index = random.randint(0, file_tok_len - chunk_len -1)\n",
        "    end_index = start_index + chunk_len + 1\n",
        "    return file_tok[start_index:end_index]\n",
        "  \n",
        "n_samples = file_tok_len // chunk_len; n_samples, file_tok_len"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(198, 79544)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UaOPvn0rXM5Z"
      },
      "source": [
        "Każdy 'kawałek' zostanie przekształcony w tensor, a dokładnie w `LongTensor` (używany do wartości całkowitych), poprzez przepuszczenie wszystkich tokenów ciągu i wyszukiwanie indeksu każdej sylaby w `all_tokens`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q0H2nwMMXM5a"
      },
      "source": [
        "# Turn token list into list of longs\n",
        "def tok_tensor(token_list):\n",
        "    tensor = torch.zeros(len(token_list)).long()\n",
        "    for c in range(len(token_list)):\n",
        "        tensor[c] = tok2idx(token_list[c])\n",
        "    \n",
        "    return Variable(to_gpu(tensor))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zrTEI7EjyyX2",
        "outputId": "09613e69-b910-40ff-b42b-c6468a81482e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "tekst = 'Litwo! Ojczyzno moja! ty jesteś jak zdrowie;'\n",
        "tekst_tok = str2syl2tok(tekst)\n",
        "print(tekst_tok)\n",
        "print(tok_tensor(tekst_tok))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['_cap_', 'lit++', '--wo', '!', '_cap_', 'oj++', '--czyz++', '--no', 'mo++', '--ja', '!', 'ty', 'je++', '--s++', '--teś', 'jak', 'zdro++', '--wie', ';']\n",
            "tensor([2721, 3565, 2396,    4, 2721, 3776,  435, 1424, 3642,  865,    4, 4468,\n",
            "        3365, 1738, 2151, 3354, 4810, 2332, 2716], device='cuda:0')\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0Su49JvFXM5d"
      },
      "source": [
        "Wreszcie możemy zmontować parę tensorów wejściowych i docelowych do treningu, z losowego kawałka. Wejściem zostaną wszystkie tokeny * aż do przedostatniego*, a celem (targetem) będą wszystkie tokeny * od drugiego*. Jeśli więc nasz kawałek to \"abc\", wejście będzie odpowiadać \"ab\", podczas gdy cel to \"bc\"."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mLzzsbTRXM5d",
        "outputId": "88637cab-dc4d-48cb-c2f9-5cd9b25402e4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "def random_training_set():  \n",
        "    chunk = random_chunk()\n",
        "    inp = tok_tensor(chunk[:-1])\n",
        "    target = tok_tensor(chunk[1:])\n",
        "    return inp, target\n",
        "  \n",
        "inp, target = random_training_set(); inp[:9], target[:9]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([4439, 2283,   10, 2722, 2721, 2832,  605, 4107, 4427], device='cuda:0'),\n",
              " tensor([2283,   10, 2722, 2721, 2832,  605, 4107, 4427,  977], device='cuda:0'))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vSJ_szQTXM5f"
      },
      "source": [
        "### Ewaluacja wyników\n",
        "\n",
        "Aby ocenić sieć, będziemy podawać po jednym tokenie na raz, wykorzystywać wyjścia sieci jako rozkład prawdopodobieństwa dla następnego znaku i powtarzać. Aby rozpocząć generowanie, przekazujemy ciąg wstępny, aby rozpocząć budowanie stanu ukrytego, z którego następnie generujemy po jednym tokenie na raz."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2ecqC4rWXM5f"
      },
      "source": [
        "def evaluate(prime_tokl=[all_tokens[1]], predict_len=100, temperature=0.8):\n",
        "    hidden = decoder.init_hidden()\n",
        "    prime_input = tok_tensor(prime_tokl)\n",
        "    predicted = list(prime_tokl)  # need a copy of the list\n",
        "\n",
        "    # Use priming token list to \"build up\" hidden state\n",
        "    for p in range(len(prime_tokl) - 1):\n",
        "        _, hidden = decoder(prime_input[p], hidden)\n",
        "    inp = prime_input[-1]\n",
        "    \n",
        "    for p in range(predict_len):\n",
        "        output, hidden = decoder(inp, hidden)\n",
        "        \n",
        "        # Sample from the network as a multinomial distribution\n",
        "        output_dist = output.data.view(-1).div(temperature).exp()\n",
        "        \n",
        "        # in pytorch 0.4.0 max, min fail if there are Infs or nans\n",
        "        # https://github.com/pytorch/pytorch/issues/6996\n",
        "        # in all pytorch versions multinomial fails if there are Infs or nans\n",
        "        # https://github.com/pytorch/pytorch/issues/871\n",
        "        # temp fix, kill Infs and nans\n",
        "        # https://discuss.pytorch.org/t/how-to-set-inf-in-tensor-variable-to-0/10235\n",
        "        output_dist[output_dist == float(\"Inf\")] = 0\n",
        "        output_dist[output_dist == float(\"nan\")] = 0\n",
        "        \n",
        "        top_i = torch.multinomial(output_dist, 1)[0].item()\n",
        "        \n",
        "        # Add predicted token to the list and use as next input\n",
        "        predicted_token = all_tokens[top_i]\n",
        "        predicted.append(predicted_token)\n",
        "        inp = tok_tensor([predicted_token])\n",
        "\n",
        "    return predicted"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lZY0fPgEXM5h"
      },
      "source": [
        "## Trening sieci"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-pM5T97tXM5h"
      },
      "source": [
        "Funkcja pomocnicza do wydrukowania upływającego czasu:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hQnLeX-TXM5h"
      },
      "source": [
        "def time_since(since):\n",
        "    s = time.time() - since\n",
        "    m = math.floor(s / 60)\n",
        "    s -= m * 60\n",
        "    return '%dm %ds' % (m, s)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0pntPTWEXM5i"
      },
      "source": [
        "Główna funkcja treningowa:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QKb7-MeXXM5j"
      },
      "source": [
        "def train(inp, target):\n",
        "    hidden = decoder.init_hidden()\n",
        "    decoder.zero_grad()\n",
        "    loss = 0\n",
        "\n",
        "    for c in range(chunk_len):\n",
        "        output, hidden = decoder(inp[c], hidden)\n",
        "        loss += criterion(output, target[c].expand(1))\n",
        "\n",
        "    loss.backward()\n",
        "    decoder_optimizer.step()\n",
        "\n",
        "    return loss.item() / chunk_len"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2EiZtEsA0571"
      },
      "source": [
        "Opcjonalny monitoring postępu treningu:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HpYR9j3qyyYF"
      },
      "source": [
        "USE_VISDOM = False\n",
        "\n",
        "vis = None\n",
        "if USE_VISDOM:\n",
        "    import visdom\n",
        "    vis = visdom.Visdom(port=8890)\n",
        "\n",
        "def vis_update_line_chart(vis, name, x, y, first_step):\n",
        "    if not USE_VISDOM: return\n",
        "    vis.line(Y=np.array([y]), X=np.array([x]), win=name, opts=dict(title=name),\n",
        "             update=None if first_step else 'append')\n",
        "\n",
        "def vis_update_text_win(vis, name, text):\n",
        "    if not USE_VISDOM: return\n",
        "    vis.text(text, win=name, opts=dict(title=name), append=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5sjJFcYJDzZ2"
      },
      "source": [
        "Wskaźnik liczby sylab, z których nie dało się skleić słów:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tY2U1vt4yyYK"
      },
      "source": [
        "def bad_words(e_syl): e_str = syl2str(e_syl); return (e_str.count('++') + e_str.count('--')) / len(e_syl)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tyo69fakXM5k"
      },
      "source": [
        "Następnie definiujemy parametry treningowe i rozpoczynamy trening:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ILThkaRPXM5k",
        "outputId": "d7cabfb3-9935-4bb8-d532-5350d1f6a725",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "n_epochs = 1\n",
        "n_iters = n_epochs * n_samples\n",
        "print_every = n_samples // 2\n",
        "plot_every = n_samples // 4\n",
        "hidden_size = 500\n",
        "n_layers = 3\n",
        "lr = 0.001\n",
        "\n",
        "decoder = RNN(n_tokens, hidden_size, n_tokens, n_layers)\n",
        "if USE_GPU:\n",
        "    decoder.cuda()\n",
        "print(decoder, flush=True)\n",
        "\n",
        "decoder_optimizer = torch.optim.Adam(decoder.parameters(), lr=lr)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "if USE_GPU:\n",
        "    criterion.cuda()\n",
        "\n",
        "all_losses = []\n",
        "loss_avg = 0\n",
        "all_bw = []\n",
        "bw_avg = 0\n",
        "\n",
        "iterable = range(1, n_iters + 1)\n",
        "tqdm_ = tqdm(iterable, '', leave=False, dynamic_ncols=True, mininterval=1.0, ascii=True, miniters=1)\n",
        "first_step = True\n",
        "\n",
        "prime_tok = str2syl2tok('Litwo! Ojczyzno moja!')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "RNN(\n",
            "  (encoder): Embedding(5059, 500)\n",
            "  (gru): GRU(500, 500, num_layers=3)\n",
            "  (decoder): Linear(in_features=500, out_features=5059, bias=True)\n",
            ")\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "  0%|          | 0/198 [00:00<?, ?it/s]\u001b[A"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R6y2kdZUj2bw",
        "outputId": "82898ab2-0463-4907-b7cc-73291f479122",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "start = time.time()\n",
        "\n",
        "for it in tqdm_:\n",
        "    epoch = 1 + it // n_samples\n",
        "    loss = train(*random_training_set())       \n",
        "    loss_avg += loss\n",
        "\n",
        "    # current loss chart\n",
        "    vis_update_line_chart(vis, 'loss', it, loss, it == 1)\n",
        "\n",
        "    # bad words    \n",
        "    bw = bad_words(evaluate(prime_tok, 100))\n",
        "    bw_avg += bw\n",
        "\n",
        "    # current bad words chart\n",
        "    vis_update_line_chart(vis, 'bad_words', it, bw, it == 1)\n",
        "    \n",
        "    # progress_bar\n",
        "    tqdm_.set_postfix({'epoch': f'{epoch}/{n_epochs}', 'loss': loss, 'bw': bw})\n",
        "    text = f'&nbsp;<font color=\"red\">{tqdm_}</font>'\n",
        "    vis_update_text_win(vis, 'progress_bar', text)\n",
        "\n",
        "    if it % print_every == 0:\n",
        "        e_syl = evaluate(prime_tok, 1000)\n",
        "        e_bw = bad_words(e_syl)\n",
        "        stats_str = '\\n[%s (%d %d %d%%) loss=%.4f bw=%.4f]' % (time_since(start), epoch, it, it / n_iters * 100, loss, e_bw)\n",
        "        print(stats_str)\n",
        "        \n",
        "        e_str = fix_punctuation(decode_tokens(syl2str(e_syl, delim='')))\n",
        "        e_html = format_html(e_str); display(HTML(e_html))\n",
        "        print(flush=True)        \n",
        "        \n",
        "        text = f'<b>{stats_str}</b><br />{e_html}'\n",
        "        vis_update_text_win(vis, 'evaluation', text)\n",
        "        \n",
        "        e_syl_path = tmp_path / 'e_syl.txt'\n",
        "        e_syl_path.open('w').write(' '.join(e_syl))\n",
        "\n",
        "    if it % plot_every == 0:\n",
        "        vis_update_line_chart(vis, 'loss_avg', it, loss_avg / plot_every, first_step)\n",
        "        vis_update_line_chart(vis, 'bad_words_avg', it, bw_avg / plot_every, first_step)\n",
        "        all_bw.append(bw)\n",
        "        bw_avg = 0\n",
        "        first_step = False\n",
        "        all_losses.append(loss_avg / plot_every)\n",
        "        loss_avg = 0"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "  0%|          | 0/198 [00:01<?, ?it/s, epoch=1/1, loss=8.53, bw=0.459]\u001b[A\n",
            "  1%|          | 1/198 [00:01<05:08,  1.57s/it, epoch=1/1, loss=8.53, bw=0.459]\u001b[A\n",
            "  1%|          | 1/198 [00:02<05:08,  1.57s/it, epoch=1/1, loss=8.44, bw=0.55] \u001b[A\n",
            "  1%|          | 1/198 [00:02<05:08,  1.57s/it, epoch=1/1, loss=8.28, bw=0.405]\u001b[A\n",
            "  2%|1         | 3/198 [00:02<04:11,  1.29s/it, epoch=1/1, loss=8.28, bw=0.405]\u001b[A\n",
            "  2%|1         | 3/198 [00:03<04:11,  1.29s/it, epoch=1/1, loss=7.68, bw=0.18] \u001b[A\n",
            "  2%|1         | 3/198 [00:04<04:11,  1.29s/it, epoch=1/1, loss=7.31, bw=0.324]\u001b[A\n",
            "  3%|2         | 5/198 [00:04<03:31,  1.10s/it, epoch=1/1, loss=7.31, bw=0.324]\u001b[A\n",
            "  3%|2         | 5/198 [00:04<03:31,  1.10s/it, epoch=1/1, loss=7.06, bw=0.324]\u001b[A\n",
            "  3%|2         | 5/198 [00:05<03:31,  1.10s/it, epoch=1/1, loss=7.07, bw=0.315]\u001b[A\n",
            "  4%|3         | 7/198 [00:05<03:03,  1.04it/s, epoch=1/1, loss=7.07, bw=0.315]\u001b[A\n",
            "  4%|3         | 7/198 [00:06<03:03,  1.04it/s, epoch=1/1, loss=6.79, bw=0.405]\u001b[A\n",
            "  4%|3         | 7/198 [00:06<03:03,  1.04it/s, epoch=1/1, loss=6.81, bw=0.387]\u001b[A\n",
            "  5%|4         | 9/198 [00:06<02:43,  1.16it/s, epoch=1/1, loss=6.81, bw=0.387]\u001b[A\n",
            "  5%|4         | 9/198 [00:07<02:43,  1.16it/s, epoch=1/1, loss=6.74, bw=0.396]\u001b[A\n",
            "  5%|4         | 9/198 [00:08<02:43,  1.16it/s, epoch=1/1, loss=6.75, bw=0.423]\u001b[A\n",
            "  6%|5         | 11/198 [00:08<02:29,  1.25it/s, epoch=1/1, loss=6.75, bw=0.423]\u001b[A\n",
            "  6%|5         | 11/198 [00:08<02:29,  1.25it/s, epoch=1/1, loss=6.68, bw=0.351]\u001b[A\n",
            "  6%|5         | 11/198 [00:09<02:29,  1.25it/s, epoch=1/1, loss=6.82, bw=0.432]\u001b[A\n",
            "  7%|6         | 13/198 [00:09<02:19,  1.32it/s, epoch=1/1, loss=6.82, bw=0.432]\u001b[A\n",
            "  7%|6         | 13/198 [00:09<02:19,  1.32it/s, epoch=1/1, loss=6.37, bw=0.369]\u001b[A\n",
            "  7%|6         | 13/198 [00:10<02:19,  1.32it/s, epoch=1/1, loss=6.61, bw=0.369]\u001b[A\n",
            "  8%|7         | 15/198 [00:10<02:11,  1.39it/s, epoch=1/1, loss=6.61, bw=0.369]\u001b[A\n",
            "  8%|7         | 15/198 [00:11<02:11,  1.39it/s, epoch=1/1, loss=6.63, bw=0.414]\u001b[A\n",
            "  8%|7         | 15/198 [00:11<02:11,  1.39it/s, epoch=1/1, loss=6.03, bw=0.369]\u001b[A\n",
            "  9%|8         | 17/198 [00:11<02:06,  1.43it/s, epoch=1/1, loss=6.03, bw=0.369]\u001b[A\n",
            "  9%|8         | 17/198 [00:12<02:06,  1.43it/s, epoch=1/1, loss=6.69, bw=0.405]\u001b[A\n",
            "  9%|8         | 17/198 [00:13<02:06,  1.43it/s, epoch=1/1, loss=6.59, bw=0.36] \u001b[A\n",
            " 10%|9         | 19/198 [00:13<02:02,  1.46it/s, epoch=1/1, loss=6.59, bw=0.36]\u001b[A\n",
            " 10%|9         | 19/198 [00:13<02:02,  1.46it/s, epoch=1/1, loss=6.73, bw=0.378]\u001b[A\n",
            " 10%|9         | 19/198 [00:14<02:02,  1.46it/s, epoch=1/1, loss=6.44, bw=0.387]\u001b[A\n",
            " 11%|#         | 21/198 [00:14<01:59,  1.48it/s, epoch=1/1, loss=6.44, bw=0.387]\u001b[A\n",
            " 11%|#         | 21/198 [00:15<01:59,  1.48it/s, epoch=1/1, loss=6.52, bw=0.396]\u001b[A\n",
            " 11%|#         | 21/198 [00:15<01:59,  1.48it/s, epoch=1/1, loss=6.61, bw=0.396]\u001b[A\n",
            " 12%|#1        | 23/198 [00:15<01:56,  1.50it/s, epoch=1/1, loss=6.61, bw=0.396]\u001b[A\n",
            " 12%|#1        | 23/198 [00:16<01:56,  1.50it/s, epoch=1/1, loss=6.27, bw=0.324]\u001b[A\n",
            " 12%|#1        | 23/198 [00:17<01:56,  1.50it/s, epoch=1/1, loss=6.55, bw=0.369]\u001b[A\n",
            " 13%|#2        | 25/198 [00:17<01:53,  1.52it/s, epoch=1/1, loss=6.55, bw=0.369]\u001b[A\n",
            " 13%|#2        | 25/198 [00:17<01:53,  1.52it/s, epoch=1/1, loss=6.52, bw=0.405]\u001b[A\n",
            " 13%|#2        | 25/198 [00:18<01:53,  1.52it/s, epoch=1/1, loss=6.79, bw=0.333]\u001b[A\n",
            " 14%|#3        | 27/198 [00:18<01:52,  1.53it/s, epoch=1/1, loss=6.79, bw=0.333]\u001b[A\n",
            " 14%|#3        | 27/198 [00:19<01:52,  1.53it/s, epoch=1/1, loss=6.51, bw=0.279]\u001b[A\n",
            " 14%|#3        | 27/198 [00:19<01:52,  1.53it/s, epoch=1/1, loss=6.37, bw=0.369]\u001b[A\n",
            " 15%|#4        | 29/198 [00:19<01:50,  1.53it/s, epoch=1/1, loss=6.37, bw=0.369]\u001b[A\n",
            " 15%|#4        | 29/198 [00:20<01:50,  1.53it/s, epoch=1/1, loss=6.51, bw=0.333]\u001b[A\n",
            " 15%|#4        | 29/198 [00:20<01:50,  1.53it/s, epoch=1/1, loss=6.33, bw=0.351]\u001b[A\n",
            " 16%|#5        | 31/198 [00:20<01:48,  1.54it/s, epoch=1/1, loss=6.33, bw=0.351]\u001b[A\n",
            " 16%|#5        | 31/198 [00:21<01:48,  1.54it/s, epoch=1/1, loss=6.35, bw=0.342]\u001b[A\n",
            " 16%|#5        | 31/198 [00:22<01:48,  1.54it/s, epoch=1/1, loss=6.38, bw=0.369]\u001b[A\n",
            " 17%|#6        | 33/198 [00:22<01:46,  1.54it/s, epoch=1/1, loss=6.38, bw=0.369]\u001b[A\n",
            " 17%|#6        | 33/198 [00:22<01:46,  1.54it/s, epoch=1/1, loss=6.47, bw=0.243]\u001b[A\n",
            " 17%|#6        | 33/198 [00:23<01:46,  1.54it/s, epoch=1/1, loss=6.1, bw=0.369] \u001b[A\n",
            " 18%|#7        | 35/198 [00:23<01:45,  1.55it/s, epoch=1/1, loss=6.1, bw=0.369]\u001b[A\n",
            " 18%|#7        | 35/198 [00:24<01:45,  1.55it/s, epoch=1/1, loss=6.3, bw=0.315]\u001b[A\n",
            " 18%|#7        | 35/198 [00:24<01:45,  1.55it/s, epoch=1/1, loss=6.31, bw=0.261]\u001b[A\n",
            " 19%|#8        | 37/198 [00:24<01:43,  1.55it/s, epoch=1/1, loss=6.31, bw=0.261]\u001b[A\n",
            " 19%|#8        | 37/198 [00:25<01:43,  1.55it/s, epoch=1/1, loss=6.37, bw=0.414]\u001b[A\n",
            " 19%|#8        | 37/198 [00:26<01:43,  1.55it/s, epoch=1/1, loss=6.43, bw=0.306]\u001b[A\n",
            " 20%|#9        | 39/198 [00:26<01:42,  1.55it/s, epoch=1/1, loss=6.43, bw=0.306]\u001b[A\n",
            " 20%|#9        | 39/198 [00:26<01:42,  1.55it/s, epoch=1/1, loss=6.15, bw=0.279]\u001b[A\n",
            " 20%|#9        | 39/198 [00:27<01:42,  1.55it/s, epoch=1/1, loss=6.35, bw=0.396]\u001b[A\n",
            " 21%|##        | 41/198 [00:27<01:41,  1.55it/s, epoch=1/1, loss=6.35, bw=0.396]\u001b[A\n",
            " 21%|##        | 41/198 [00:28<01:41,  1.55it/s, epoch=1/1, loss=6.25, bw=0.378]\u001b[A\n",
            " 21%|##        | 41/198 [00:28<01:41,  1.55it/s, epoch=1/1, loss=6.6, bw=0.387] \u001b[A\n",
            " 22%|##1       | 43/198 [00:28<01:39,  1.55it/s, epoch=1/1, loss=6.6, bw=0.387]\u001b[A\n",
            " 22%|##1       | 43/198 [00:29<01:39,  1.55it/s, epoch=1/1, loss=6.16, bw=0.387]\u001b[A\n",
            " 22%|##1       | 43/198 [00:29<01:39,  1.55it/s, epoch=1/1, loss=6.12, bw=0.288]\u001b[A\n",
            " 23%|##2       | 45/198 [00:29<01:38,  1.55it/s, epoch=1/1, loss=6.12, bw=0.288]\u001b[A\n",
            " 23%|##2       | 45/198 [00:30<01:38,  1.55it/s, epoch=1/1, loss=6.38, bw=0.441]\u001b[A\n",
            " 23%|##2       | 45/198 [00:31<01:38,  1.55it/s, epoch=1/1, loss=6, bw=0.396]   \u001b[A\n",
            " 24%|##3       | 47/198 [00:31<01:37,  1.55it/s, epoch=1/1, loss=6, bw=0.396]\u001b[A\n",
            " 24%|##3       | 47/198 [00:31<01:37,  1.55it/s, epoch=1/1, loss=6.27, bw=0.342]\u001b[A\n",
            " 24%|##3       | 47/198 [00:32<01:37,  1.55it/s, epoch=1/1, loss=6.24, bw=0.324]\u001b[A\n",
            " 25%|##4       | 49/198 [00:32<01:36,  1.55it/s, epoch=1/1, loss=6.24, bw=0.324]\u001b[A\n",
            " 25%|##4       | 49/198 [00:33<01:36,  1.55it/s, epoch=1/1, loss=6.3, bw=0.333] \u001b[A\n",
            " 25%|##4       | 49/198 [00:33<01:36,  1.55it/s, epoch=1/1, loss=6.16, bw=0.459]\u001b[A\n",
            " 26%|##5       | 51/198 [00:33<01:34,  1.55it/s, epoch=1/1, loss=6.16, bw=0.459]\u001b[A\n",
            " 26%|##5       | 51/198 [00:34<01:34,  1.55it/s, epoch=1/1, loss=6.36, bw=0.45] \u001b[A\n",
            " 26%|##5       | 51/198 [00:35<01:34,  1.55it/s, epoch=1/1, loss=6.19, bw=0.333]\u001b[A\n",
            " 27%|##6       | 53/198 [00:35<01:34,  1.53it/s, epoch=1/1, loss=6.19, bw=0.333]\u001b[A\n",
            " 27%|##6       | 53/198 [00:35<01:34,  1.53it/s, epoch=1/1, loss=6.18, bw=0.369]\u001b[A\n",
            " 27%|##6       | 53/198 [00:36<01:34,  1.53it/s, epoch=1/1, loss=6.04, bw=0.405]\u001b[A\n",
            " 28%|##7       | 55/198 [00:36<01:32,  1.54it/s, epoch=1/1, loss=6.04, bw=0.405]\u001b[A\n",
            " 28%|##7       | 55/198 [00:37<01:32,  1.54it/s, epoch=1/1, loss=6, bw=0.369]   \u001b[A\n",
            " 28%|##7       | 55/198 [00:37<01:32,  1.54it/s, epoch=1/1, loss=6.19, bw=0.333]\u001b[A\n",
            " 29%|##8       | 57/198 [00:37<01:31,  1.54it/s, epoch=1/1, loss=6.19, bw=0.333]\u001b[A\n",
            " 29%|##8       | 57/198 [00:38<01:31,  1.54it/s, epoch=1/1, loss=5.74, bw=0.396]\u001b[A\n",
            " 29%|##8       | 57/198 [00:39<01:31,  1.54it/s, epoch=1/1, loss=6.24, bw=0.36] \u001b[A\n",
            " 30%|##9       | 59/198 [00:39<01:29,  1.55it/s, epoch=1/1, loss=6.24, bw=0.36]\u001b[A\n",
            " 30%|##9       | 59/198 [00:39<01:29,  1.55it/s, epoch=1/1, loss=6.09, bw=0.36]\u001b[A\n",
            " 30%|##9       | 59/198 [00:40<01:29,  1.55it/s, epoch=1/1, loss=5.9, bw=0.36] \u001b[A\n",
            " 31%|###       | 61/198 [00:40<01:28,  1.54it/s, epoch=1/1, loss=5.9, bw=0.36]\u001b[A\n",
            " 31%|###       | 61/198 [00:40<01:28,  1.54it/s, epoch=1/1, loss=6.08, bw=0.369]\u001b[A\n",
            " 31%|###       | 61/198 [00:41<01:28,  1.54it/s, epoch=1/1, loss=6.18, bw=0.396]\u001b[A\n",
            " 32%|###1      | 63/198 [00:41<01:27,  1.54it/s, epoch=1/1, loss=6.18, bw=0.396]\u001b[A\n",
            " 32%|###1      | 63/198 [00:42<01:27,  1.54it/s, epoch=1/1, loss=6.2, bw=0.441] \u001b[A\n",
            " 32%|###1      | 63/198 [00:42<01:27,  1.54it/s, epoch=1/1, loss=5.95, bw=0.342]\u001b[A\n",
            " 33%|###2      | 65/198 [00:42<01:25,  1.55it/s, epoch=1/1, loss=5.95, bw=0.342]\u001b[A\n",
            " 33%|###2      | 65/198 [00:43<01:25,  1.55it/s, epoch=1/1, loss=6.19, bw=0.351]\u001b[A\n",
            " 33%|###2      | 65/198 [00:44<01:25,  1.55it/s, epoch=1/1, loss=6.11, bw=0.387]\u001b[A\n",
            " 34%|###3      | 67/198 [00:44<01:24,  1.55it/s, epoch=1/1, loss=6.11, bw=0.387]\u001b[A\n",
            " 34%|###3      | 67/198 [00:44<01:24,  1.55it/s, epoch=1/1, loss=6.01, bw=0.414]\u001b[A\n",
            " 34%|###3      | 67/198 [00:45<01:24,  1.55it/s, epoch=1/1, loss=6.1, bw=0.324] \u001b[A\n",
            " 35%|###4      | 69/198 [00:45<01:23,  1.54it/s, epoch=1/1, loss=6.1, bw=0.324]\u001b[A\n",
            " 35%|###4      | 69/198 [00:46<01:23,  1.54it/s, epoch=1/1, loss=6.09, bw=0.405]\u001b[A\n",
            " 35%|###4      | 69/198 [00:46<01:23,  1.54it/s, epoch=1/1, loss=6.2, bw=0.369] \u001b[A\n",
            " 36%|###5      | 71/198 [00:46<01:22,  1.54it/s, epoch=1/1, loss=6.2, bw=0.369]\u001b[A\n",
            " 36%|###5      | 71/198 [00:47<01:22,  1.54it/s, epoch=1/1, loss=6.08, bw=0.351]\u001b[A\n",
            " 36%|###5      | 71/198 [00:48<01:22,  1.54it/s, epoch=1/1, loss=6, bw=0.288]   \u001b[A\n",
            " 37%|###6      | 73/198 [00:48<01:21,  1.54it/s, epoch=1/1, loss=6, bw=0.288]\u001b[A\n",
            " 37%|###6      | 73/198 [00:48<01:21,  1.54it/s, epoch=1/1, loss=6.29, bw=0.441]\u001b[A\n",
            " 37%|###6      | 73/198 [00:49<01:21,  1.54it/s, epoch=1/1, loss=6.05, bw=0.396]\u001b[A\n",
            " 38%|###7      | 75/198 [00:49<01:20,  1.53it/s, epoch=1/1, loss=6.05, bw=0.396]\u001b[A\n",
            " 38%|###7      | 75/198 [00:50<01:20,  1.53it/s, epoch=1/1, loss=6.24, bw=0.315]\u001b[A\n",
            " 38%|###7      | 75/198 [00:50<01:20,  1.53it/s, epoch=1/1, loss=5.64, bw=0.351]\u001b[A\n",
            " 39%|###8      | 77/198 [00:50<01:19,  1.53it/s, epoch=1/1, loss=5.64, bw=0.351]\u001b[A\n",
            " 39%|###8      | 77/198 [00:51<01:19,  1.53it/s, epoch=1/1, loss=6.1, bw=0.342] \u001b[A\n",
            " 39%|###8      | 77/198 [00:52<01:19,  1.53it/s, epoch=1/1, loss=5.96, bw=0.405]\u001b[A\n",
            " 40%|###9      | 79/198 [00:52<01:18,  1.52it/s, epoch=1/1, loss=5.96, bw=0.405]\u001b[A\n",
            " 40%|###9      | 79/198 [00:52<01:18,  1.52it/s, epoch=1/1, loss=5.91, bw=0.378]\u001b[A\n",
            " 40%|###9      | 79/198 [00:53<01:18,  1.52it/s, epoch=1/1, loss=5.95, bw=0.342]\u001b[A\n",
            " 41%|####      | 81/198 [00:53<01:16,  1.52it/s, epoch=1/1, loss=5.95, bw=0.342]\u001b[A\n",
            " 41%|####      | 81/198 [00:54<01:16,  1.52it/s, epoch=1/1, loss=6.03, bw=0.342]\u001b[A\n",
            " 41%|####      | 81/198 [00:54<01:16,  1.52it/s, epoch=1/1, loss=5.95, bw=0.297]\u001b[A\n",
            " 42%|####1     | 83/198 [00:54<01:15,  1.53it/s, epoch=1/1, loss=5.95, bw=0.297]\u001b[A\n",
            " 42%|####1     | 83/198 [00:55<01:15,  1.53it/s, epoch=1/1, loss=6.1, bw=0.387] \u001b[A\n",
            " 42%|####1     | 83/198 [00:56<01:15,  1.53it/s, epoch=1/1, loss=5.92, bw=0.369]\u001b[A\n",
            " 43%|####2     | 85/198 [00:56<01:14,  1.53it/s, epoch=1/1, loss=5.92, bw=0.369]\u001b[A\n",
            " 43%|####2     | 85/198 [00:56<01:14,  1.53it/s, epoch=1/1, loss=5.97, bw=0.342]\u001b[A\n",
            " 43%|####2     | 85/198 [00:57<01:14,  1.53it/s, epoch=1/1, loss=6.11, bw=0.369]\u001b[A\n",
            " 44%|####3     | 87/198 [00:57<01:12,  1.54it/s, epoch=1/1, loss=6.11, bw=0.369]\u001b[A\n",
            " 44%|####3     | 87/198 [00:57<01:12,  1.54it/s, epoch=1/1, loss=6.19, bw=0.378]\u001b[A\n",
            " 44%|####3     | 87/198 [00:58<01:12,  1.54it/s, epoch=1/1, loss=6.48, bw=0.315]\u001b[A\n",
            " 45%|####4     | 89/198 [00:58<01:10,  1.54it/s, epoch=1/1, loss=6.48, bw=0.315]\u001b[A\n",
            " 45%|####4     | 89/198 [00:59<01:10,  1.54it/s, epoch=1/1, loss=6.17, bw=0.351]\u001b[A\n",
            " 45%|####4     | 89/198 [00:59<01:10,  1.54it/s, epoch=1/1, loss=5.89, bw=0.315]\u001b[A\n",
            " 46%|####5     | 91/198 [00:59<01:09,  1.54it/s, epoch=1/1, loss=5.89, bw=0.315]\u001b[A\n",
            " 46%|####5     | 91/198 [01:00<01:09,  1.54it/s, epoch=1/1, loss=5.89, bw=0.324]\u001b[A\n",
            " 46%|####5     | 91/198 [01:01<01:09,  1.54it/s, epoch=1/1, loss=5.91, bw=0.252]\u001b[A\n",
            " 47%|####6     | 93/198 [01:01<01:08,  1.54it/s, epoch=1/1, loss=5.91, bw=0.252]\u001b[A\n",
            " 47%|####6     | 93/198 [01:01<01:08,  1.54it/s, epoch=1/1, loss=6.21, bw=0.315]\u001b[A\n",
            " 47%|####6     | 93/198 [01:02<01:08,  1.54it/s, epoch=1/1, loss=6.23, bw=0.315]\u001b[A\n",
            " 48%|####7     | 95/198 [01:02<01:06,  1.54it/s, epoch=1/1, loss=6.23, bw=0.315]\u001b[A\n",
            " 48%|####7     | 95/198 [01:03<01:06,  1.54it/s, epoch=1/1, loss=6.11, bw=0.342]\u001b[A\n",
            " 48%|####7     | 95/198 [01:03<01:06,  1.54it/s, epoch=1/1, loss=5.95, bw=0.315]\u001b[A\n",
            " 49%|####8     | 97/198 [01:03<01:05,  1.54it/s, epoch=1/1, loss=5.95, bw=0.315]\u001b[A\n",
            " 49%|####8     | 97/198 [01:04<01:05,  1.54it/s, epoch=1/1, loss=5.88, bw=0.432]\u001b[A\n",
            " 49%|####8     | 97/198 [01:05<01:05,  1.54it/s, epoch=1/1, loss=6.23, bw=0.369]\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "[1m 5s (1 99 50%) loss=6.2304 bw=0.3828]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "Litwo! Ojczyzno moja! \n",
              "<br/><font color=\"red\">--</font>Wiąc <font color=\"red\">--</font>cu dal<font color=\"red\">++</font> się, swym nas <font color=\"red\">--</font>naną <font color=\"red\">--</font>bi<font color=\"red\">++</font> \n",
              "<br/>I idą moc blis<font color=\"red\">++</font> za brał <font color=\"red\">--</font>jąc, <font color=\"red\">--</font>wio<font color=\"red\">++</font>, uszy <font color=\"red\">--</font>chać <font color=\"red\">--</font>ło, \n",
              "<br/>, as<font color=\"red\">++</font> tego <font color=\"red\">--</font>gieldon <font color=\"red\">--</font>no<font color=\"red\">++</font> na <font color=\"red\">--</font>znał <font color=\"red\">--</font>wał <font color=\"red\">--</font>ka \n",
              "<br/>I ro<font color=\"red\">++</font> też tę<font color=\"red\">++</font> woź<font color=\"red\">++</font>; \n",
              "<br/><font color=\"red\">--</font>Likich o<font color=\"red\">++</font> ko<font color=\"red\">++</font> mó<font color=\"red\">++</font> w od rozrys<font color=\"red\">++</font> gło<font color=\"red\">++</font>, \n",
              "<br/>Padła<font color=\"red\">++</font> w słusz<font color=\"red\">++</font> xię<font color=\"red\">++</font> saje, że też w stawaciaż, \n",
              "<br/><font color=\"red\">--</font>Gdzie <font color=\"red\">--</font>szy <font color=\"red\">--</font>ło <font color=\"red\">--</font>ję stara<font color=\"red\">++</font> Tu <font color=\"red\">--</font>ku w jest co sa<font color=\"red\">++</font>, Sę<font color=\"red\">++</font> i, czarwet <font color=\"red\">--</font>sił <font color=\"red\">--</font>bieło<font color=\"red\">++</font>; \n",
              "<br/>Pod<font color=\"red\">++</font> są <font color=\"red\">--</font>dę <font color=\"red\">--</font>kła<font color=\"red\">++</font> strzel<font color=\"red\">++</font> lit<font color=\"red\">++</font> na łą<font color=\"red\">++</font> ich zwamy <font color=\"red\">--</font>tu<font color=\"red\">++</font> nieki: \n",
              "<br/><font color=\"red\">--</font>Ną <font color=\"red\">--</font>go <font color=\"red\">--</font>marasdzici <font color=\"red\">--</font>ją znikkiéj <font color=\"red\">--</font>wny, \n",
              "<br/>Ulów, <font color=\"red\">--</font>łu jeni <font color=\"red\">--</font>dzi<font color=\"red\">++</font> po<font color=\"red\">++</font> boprzy<font color=\"red\">++</font>, tonie: czerbo \n",
              "<br/>Pan miał, Od<font color=\"red\">++</font> też <font color=\"red\">--</font>je <font color=\"red\">--</font>cał <font color=\"red\">--</font>ruła ki<font color=\"red\">++</font>, tasza strwory, \n",
              "<br/>I to ży<font color=\"red\">++</font> narania niesią jeków <font color=\"red\">--</font>ści wrób<font color=\"red\">++</font> dzienia. \n",
              "<br/>Jest i zno<font color=\"red\">++</font> niżmy litką <font color=\"red\">--</font>ła <font color=\"red\">--</font>lec <font color=\"red\">--</font>pie<font color=\"red\">++</font>, \n",
              "<br/><font color=\"red\">--</font>Stek <font color=\"red\">--</font>liło? móło <font color=\"red\">--</font>zwał <font color=\"red\">--</font>dzi, i <font color=\"red\">--</font>ko <font color=\"red\">--</font>kę tam; \n",
              "<br/>ta<font color=\"red\">++</font> zacierz po<font color=\"red\">++</font> w w nóż głoskie,, Nie<font color=\"red\">++</font> bu<font color=\"red\">++</font> s że łzach <font color=\"red\">--</font>li. \n",
              "<br/>Tesu nas <font color=\"red\">--</font>pe<font color=\"red\">++</font> a<font color=\"red\">++</font> mony <font color=\"red\">--</font>pyrząt <font color=\"red\">--</font>skie <font color=\"red\">--</font>pię, wieldzina \n",
              "<br/><font color=\"red\">--</font>Jo<font color=\"red\">++</font> zady <font color=\"red\">--</font>czmień z <font color=\"red\">--</font>giel<font color=\"red\">++</font> mochrzczo<font color=\"red\">++</font>, Więcéj <font color=\"red\">--</font>kał <font color=\"red\">--</font>szy doń <font color=\"red\">--</font>ni, \n",
              "<br/>Po<font color=\"red\">++</font> mó<font color=\"red\">++</font> ki<font color=\"red\">++</font> za<font color=\"red\">++</font> stroże <font color=\"red\">--</font>szursiad<font color=\"red\">++</font> dłu<font color=\"red\">++</font> jakgosleż, \n",
              "<br/><font color=\"red\">--</font>Deusz <font color=\"red\">--</font>li stolimach, ta<font color=\"red\">++</font> tak jak na <font color=\"red\">--</font>ców <font color=\"red\">--</font>wnąwgał so<font color=\"red\">++</font>; \n",
              "<br/>Szczę<font color=\"red\">++</font> czwaby <font color=\"red\">--</font>wistwo kodzy dwóch <font color=\"red\">--</font>ku, po<font color=\"red\">++</font>, szko<font color=\"red\">++</font> jednéj, \n",
              "<br/>Bły<font color=\"red\">++</font> spago <font color=\"red\">--</font>moka za<font color=\"red\">++</font> mórza <font color=\"red\">--</font>ki, <font color=\"red\">--</font>bić <font color=\"red\">--</font>no woże, \n",
              "<br/>Po<font color=\"red\">++</font> rała zdałem w złoś<font color=\"red\">++</font> biecze <font color=\"red\">--</font>tą po<font color=\"red\">++</font> ger<font color=\"red\">++</font> u<font color=\"red\">++</font>, \n",
              "<br/>Jaksarz się niełą<font color=\"red\">++</font> tém <font color=\"red\">--</font>wnianéj, s tema<font color=\"red\">++</font> Prze<font color=\"red\">++</font> win<font color=\"red\">++</font> post<font color=\"red\">++</font>, \n",
              "<br/>Aż <font color=\"red\">--</font>szbawań <font color=\"red\">--</font>lił twarz społa dokanty <font color=\"red\">--</font>ra<font color=\"red\">++</font>, \n",
              "<br/>W <font color=\"red\">--</font>su <font color=\"red\">--</font>bun <font color=\"red\">--</font>łem od<font color=\"red\">++</font> łokłę<font color=\"red\">++</font> niego <font color=\"red\">--</font>rzę<font color=\"red\">++</font> niższ<font color=\"red\">++</font> w rozwa<font color=\"red\">++</font> w <font color=\"red\">--</font>łu, \n",
              "<br/>Sam od jac<font color=\"red\">++</font> tylgo kór<font color=\"red\">++</font> więc nie<font color=\"red\">++</font> obwie <font color=\"red\">--</font>ła <font color=\"red\">--</font>wniejjąc. \n",
              "<br/><font color=\"red\">--</font>Nął <font color=\"red\">--</font>dar<font color=\"red\">++</font>, je<font color=\"red\">++</font> na <font color=\"red\">--</font>kie się <font color=\"red\">--</font>ną coko za<font color=\"red\">++</font> z <font color=\"red\">--</font>Że, <font color=\"red\">--</font> Rozdarz Do<font color=\"red\">++</font> choć<font color=\"red\">++</font>? \n",
              "<br/><font color=\"red\">--</font>Ła pocił poczys<font color=\"red\">++</font> ta<font color=\"red\">++</font> budzi ka<font color=\"red\">++</font> recida <font color=\"red\">--</font>ni: \n",
              "<br/>Ró<font color=\"red\">++</font> kręni naściach po<font color=\"red\">++</font> roz<font color=\"red\">++</font> niech <font color=\"red\">--</font>daci<font color=\"red\">++</font>, i bóg du<font color=\"red\">++</font>. \n",
              "<br/>Myś<font color=\"red\">++</font> za<font color=\"red\">++</font>, pa<font color=\"red\">++</font> pełwie Ni <font color=\"red\">--</font>go zarym na <font color=\"red\">--</font>me<font color=\"red\">++</font>, \n",
              "<br/>Wy<font color=\"red\">++</font>, <font color=\"red\">--</font>gą bunie u<font color=\"red\">++</font> zała się się <font color=\"red\">--</font>strzamam, \n",
              "<br/><font color=\"red\">--</font>Ka wzrowa<font color=\"red\">++</font> téj <font color=\"red\">--</font>ła za <font color=\"red\">--</font>ku <font color=\"red\">--</font>nie, <font color=\"red\">--</font>sz<font color=\"red\">++</font> wy<font color=\"red\">++</font> po<font color=\"red\">++</font> lub <font color=\"red\">--</font>go <font color=\"red\">--</font>ta<font color=\"red\">++</font>; \n",
              "<br/>W to <font color=\"red\">--</font>li<font color=\"red\">++</font> wiezysko<font color=\"red\">++</font>, <font color=\"red\">--</font>deu<font color=\"red\">++</font> kęru<font color=\"red\">++</font> ma<font color=\"red\">++</font> był. \n",
              "<br/>\n",
              "<br/>, przero<font color=\"red\">++</font> dzier<font color=\"red\">++</font> bróz<font color=\"red\">++</font>, uli <font color=\"red\">--</font>ko<font color=\"red\">++</font> wasz <font color=\"red\">--</font>wło<font color=\"red\">++</font> motu<font color=\"red\">++</font>, \n",
              "<br/>Zaszo<font color=\"red\">++</font> u<font color=\"red\">++</font> zwyla<font color=\"red\">++</font> nała stała od <font color=\"red\">--</font>dy jedném <font color=\"red\">--</font>ry, \n",
              "<br/>W <font color=\"red\">--</font>wiesem za<font color=\"red\">++</font> zmiewi<font color=\"red\">++</font> pio<font color=\"red\">++</font>. \n",
              "<br/>Ko<font color=\"red\">++</font> łąk do<font color=\"red\">++</font> bra<font color=\"red\">++</font> się <font color=\"red\">--</font>stercz<font color=\"red\">++</font> przedza<font color=\"red\">++</font>, w <font color=\"red\">--</font>ku<font color=\"red\">++</font> ku<font color=\"red\">++</font> niedził: \n",
              "<br/>Pra<font color=\"red\">++</font> ciki <font color=\"red\">--</font>ka któ<font color=\"red\">++</font> Wła<font color=\"red\">++</font> posłu<font color=\"red\">++</font>, niedziezordz<font color=\"red\">++</font> zło<font color=\"red\">++</font>. \n",
              "<br/>Tyl<font color=\"red\">++</font> i załem pan <font color=\"red\">--</font>cz<font color=\"red\">++</font> po<font color=\"red\">++</font>, owna z <font color=\"red\">--</font>ta <font color=\"red\">--</font>mień sie<font color=\"red\">++</font>, Po<font color=\"red\">++</font>, służ<font color=\"red\">++</font>, strzel<font color=\"red\">++</font> nie <font color=\"red\">--</font>te <font color=\"red\">--</font>wy. \n",
              "<br/>Tane tu<font color=\"red\">++</font> prze<font color=\"red\">++</font>, nic lit<font color=\"red\">++</font> bo <font color=\"red\">--</font>ra<font color=\"red\">++</font> ni, przegali, \n",
              "<br/>Tak <font color=\"red\">--</font>cy, <font color=\"red\">--</font>łem <font color=\"red\">--</font>dziów <font color=\"red\">--</font>gi <font color=\"red\">--</font>es<font color=\"red\">++</font> już <font color=\"red\">--</font>cho<font color=\"red\">++</font>, pa<font color=\"red\">++</font>; da<font color=\"red\">++</font> dłu<font color=\"red\">++</font>. \n",
              "<br/>Jak <font color=\"red\">--</font>deusz <font color=\"red\">--</font>wet <font color=\"red\">--</font>ku tu ob<font color=\"red\">++</font>, boki <font color=\"red\">--</font>cał, <font color=\"red\">--</font>mego <font color=\"red\">--</font>ko. \n",
              "<br/>Gopo<font color=\"red\">++</font> by<font color=\"red\">++</font>, obia <font color=\"red\">--</font>li<font color=\"red\">++</font> rzecz uku tra<font color=\"red\">++</font> że <font color=\"red\">--</font>pieli \n",
              "<br/>I ma<font color=\"red\">++</font> po<font color=\"red\">++</font> sta<font color=\"red\">++</font> w czy<font color=\"red\">++</font> w i <font color=\"red\">--</font>pu<font color=\"red\">++</font>; <font color=\"red\">--</font>lu<font color=\"red\">++</font> jéj, przydzia; \n",
              "<br/>Głoła <font color=\"red\">--</font>ne jest <font color=\"red\">--</font>go <font color=\"red\">--</font>sta<font color=\"red\">++</font>, i, u<font color=\"red\">++</font> zwol<font color=\"red\">++</font> milka, s w <font color=\"red\">--</font>me<font color=\"red\">++</font>, \n",
              "<br/>Prze<font color=\"red\">++</font> garsta, w krzewi kra<font color=\"red\">++</font> za<font color=\"red\">++</font>, i na<font color=\"red\">++</font>, na a nie<font color=\"red\">++</font> zgo<font color=\"red\">++</font>, \n",
              "<br/>Te<font color=\"red\">++</font> jeko<font color=\"red\">++</font>, że w trąb<font color=\"red\">++</font> nad <font color=\"red\">--</font>na ty<font color=\"red\">++</font>, choć jak<font color=\"red\">++</font> się ruda <font color=\"red\">--</font>ły. \n",
              "<br/>Pra<font color=\"red\">++</font> się bez <font color=\"red\">--</font>nie od kiltniów staki nas z <font color=\"red\">--</font>cież <font color=\"red\">--</font>bia. \n",
              "<br/>Odcztach, prze<font color=\"red\">++</font> wy<font color=\"red\">++</font>, <font color=\"red\">--</font>nych biko <font color=\"red\">--</font>czy nich <font color=\"red\">--</font>li co żo<font color=\"red\">++</font>; \n",
              "<br/><font color=\"red\">--</font>Czy<font color=\"red\">++</font> w swój po<font color=\"red\">++</font> zacze bakirych, <font color=\"red\">--</font>raz <font color=\"red\">--</font>ste<font color=\"red\">++</font> przyre<font color=\"red\">++</font>, \n",
              "<br/>Koń<font color=\"red\">++</font>, <font color=\"red\">--</font>mo<font color=\"red\">++</font> i co, ta<font color=\"red\">++</font> to<font color=\"red\">++</font> ro<font color=\"red\">++</font>: nasz<font color=\"red\">++</font> nas u<font color=\"red\">++</font>; \n",
              "<br/>O<font color=\"red\">++</font> sług, ścia<font color=\"red\">++</font> te<font color=\"red\">++</font> sęnie pod <font color=\"red\">--</font>ra <font color=\"red\">--</font>wą <font color=\"red\">--</font>dźwiełem za<font color=\"red\">++</font> ku<font color=\"red\">++</font>, \n",
              "<br/>Na<font color=\"red\">++</font> choć w od za<font color=\"red\">++</font> s <font color=\"red\">--</font>scią<font color=\"red\">++</font> się pa<font color=\"red\">++</font>, tym, a Wiel<font color=\"red\">++</font> pan sa<font color=\"red\">++</font> ho<font color=\"red\">++</font>, \n",
              "<br/><font color=\"red\">--</font>Cz<font color=\"red\">++</font> o<font color=\"red\">++</font> i w takich i roz<font color=\"red\">++</font>, <font color=\"red\">--</font>Wą <font color=\"red\">--</font>bia, i ro<font color=\"red\">++</font>, w, dłu<font color=\"red\">++</font> je<font color=\"red\">++</font>,,, w mi jak<font color=\"red\">++</font>. \n",
              "<br/>Wy<font color=\"red\">++</font>, ta<font color=\"red\">++</font> nie<font color=\"red\">++</font> po<font color=\"red\">++</font> księwie <font color=\"red\">--</font>wać i <font color=\"red\">--</font>by s <font color=\"red\">--</font>mi sam, \n",
              "<br/>? gdy<font color=\"red\">++</font> ta<font color=\"red\">++</font> teśmie<font color=\"red\">++</font> wy<font color=\"red\">++</font>, się wi<font color=\"red\">++</font> e<font color=\"red\">++</font> żo<font color=\"red\">++</font>, \n",
              "<br/>Jak <font color=\"red\">--</font>ko <font color=\"red\">--</font>dy <font color=\"red\">--</font>nie <font color=\"red\">--</font>ną, w <font color=\"red\">--</font>sz<font color=\"red\">++</font> donie <font color=\"red\">--</font>kien<font color=\"red\">++</font> się bynia<font color=\"red\">++</font>, na<font color=\"red\">++</font>,, <font color=\"red\">--</font>dem lał na<font color=\"red\">++</font> świena, \n",
              "<br/>, że wszczął ro<font color=\"red\">++</font>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            " 50%|#####     | 99/198 [01:06<01:18,  1.25it/s, epoch=1/1, loss=6.23, bw=0.369]\u001b[A\n",
            " 50%|#####     | 99/198 [01:06<01:18,  1.25it/s, epoch=1/1, loss=6.02, bw=0.324]\u001b[A\n",
            " 50%|#####     | 99/198 [01:07<01:18,  1.25it/s, epoch=1/1, loss=5.93, bw=0.333]\u001b[A\n",
            " 51%|#####1    | 101/198 [01:07<01:13,  1.33it/s, epoch=1/1, loss=5.93, bw=0.333]\u001b[A\n",
            " 51%|#####1    | 101/198 [01:08<01:13,  1.33it/s, epoch=1/1, loss=6.06, bw=0.306]\u001b[A\n",
            " 51%|#####1    | 101/198 [01:08<01:13,  1.33it/s, epoch=1/1, loss=6.05, bw=0.36] \u001b[A\n",
            " 52%|#####2    | 103/198 [01:08<01:08,  1.39it/s, epoch=1/1, loss=6.05, bw=0.36]\u001b[A\n",
            " 52%|#####2    | 103/198 [01:09<01:08,  1.39it/s, epoch=1/1, loss=5.82, bw=0.288]\u001b[A\n",
            " 52%|#####2    | 103/198 [01:09<01:08,  1.39it/s, epoch=1/1, loss=6.06, bw=0.288]\u001b[A\n",
            " 53%|#####3    | 105/198 [01:09<01:05,  1.43it/s, epoch=1/1, loss=6.06, bw=0.288]\u001b[A\n",
            " 53%|#####3    | 105/198 [01:10<01:05,  1.43it/s, epoch=1/1, loss=5.94, bw=0.342]\u001b[A\n",
            " 53%|#####3    | 105/198 [01:11<01:05,  1.43it/s, epoch=1/1, loss=5.96, bw=0.288]\u001b[A\n",
            " 54%|#####4    | 107/198 [01:11<01:02,  1.46it/s, epoch=1/1, loss=5.96, bw=0.288]\u001b[A\n",
            " 54%|#####4    | 107/198 [01:11<01:02,  1.46it/s, epoch=1/1, loss=5.87, bw=0.36] \u001b[A\n",
            " 54%|#####4    | 107/198 [01:12<01:02,  1.46it/s, epoch=1/1, loss=5.89, bw=0.315]\u001b[A\n",
            " 55%|#####5    | 109/198 [01:12<00:59,  1.49it/s, epoch=1/1, loss=5.89, bw=0.315]\u001b[A\n",
            " 55%|#####5    | 109/198 [01:13<00:59,  1.49it/s, epoch=1/1, loss=6.05, bw=0.288]\u001b[A\n",
            " 55%|#####5    | 109/198 [01:13<00:59,  1.49it/s, epoch=1/1, loss=5.91, bw=0.36] \u001b[A\n",
            " 56%|#####6    | 111/198 [01:13<00:57,  1.51it/s, epoch=1/1, loss=5.91, bw=0.36]\u001b[A\n",
            " 56%|#####6    | 111/198 [01:14<00:57,  1.51it/s, epoch=1/1, loss=6.37, bw=0.342]\u001b[A\n",
            " 56%|#####6    | 111/198 [01:15<00:57,  1.51it/s, epoch=1/1, loss=5.85, bw=0.324]\u001b[A\n",
            " 57%|#####7    | 113/198 [01:15<00:55,  1.52it/s, epoch=1/1, loss=5.85, bw=0.324]\u001b[A\n",
            " 57%|#####7    | 113/198 [01:15<00:55,  1.52it/s, epoch=1/1, loss=5.84, bw=0.342]\u001b[A\n",
            " 57%|#####7    | 113/198 [01:16<00:55,  1.52it/s, epoch=1/1, loss=5.96, bw=0.324]\u001b[A\n",
            " 58%|#####8    | 115/198 [01:16<00:54,  1.53it/s, epoch=1/1, loss=5.96, bw=0.324]\u001b[A\n",
            " 58%|#####8    | 115/198 [01:17<00:54,  1.53it/s, epoch=1/1, loss=5.94, bw=0.297]\u001b[A\n",
            " 58%|#####8    | 115/198 [01:17<00:54,  1.53it/s, epoch=1/1, loss=5.94, bw=0.252]\u001b[A\n",
            " 59%|#####9    | 117/198 [01:17<00:53,  1.53it/s, epoch=1/1, loss=5.94, bw=0.252]\u001b[A\n",
            " 59%|#####9    | 117/198 [01:18<00:53,  1.53it/s, epoch=1/1, loss=5.89, bw=0.243]\u001b[A\n",
            " 59%|#####9    | 117/198 [01:19<00:53,  1.53it/s, epoch=1/1, loss=5.6, bw=0.207] \u001b[A\n",
            " 60%|######    | 119/198 [01:19<00:51,  1.53it/s, epoch=1/1, loss=5.6, bw=0.207]\u001b[A\n",
            " 60%|######    | 119/198 [01:19<00:51,  1.53it/s, epoch=1/1, loss=5.76, bw=0.27]\u001b[A\n",
            " 60%|######    | 119/198 [01:20<00:51,  1.53it/s, epoch=1/1, loss=6.01, bw=0.207]\u001b[A\n",
            " 61%|######1   | 121/198 [01:20<00:50,  1.53it/s, epoch=1/1, loss=6.01, bw=0.207]\u001b[A\n",
            " 61%|######1   | 121/198 [01:20<00:50,  1.53it/s, epoch=1/1, loss=5.47, bw=0.252]\u001b[A\n",
            " 61%|######1   | 121/198 [01:21<00:50,  1.53it/s, epoch=1/1, loss=6.06, bw=0.27] \u001b[A\n",
            " 62%|######2   | 123/198 [01:21<00:49,  1.53it/s, epoch=1/1, loss=6.06, bw=0.27]\u001b[A\n",
            " 62%|######2   | 123/198 [01:22<00:49,  1.53it/s, epoch=1/1, loss=5.99, bw=0.279]\u001b[A\n",
            " 62%|######2   | 123/198 [01:22<00:49,  1.53it/s, epoch=1/1, loss=5.94, bw=0.18] \u001b[A\n",
            " 63%|######3   | 125/198 [01:22<00:47,  1.54it/s, epoch=1/1, loss=5.94, bw=0.18]\u001b[A\n",
            " 63%|######3   | 125/198 [01:23<00:47,  1.54it/s, epoch=1/1, loss=5.8, bw=0.18] \u001b[A\n",
            " 63%|######3   | 125/198 [01:24<00:47,  1.54it/s, epoch=1/1, loss=5.76, bw=0.189]\u001b[A\n",
            " 64%|######4   | 127/198 [01:24<00:46,  1.54it/s, epoch=1/1, loss=5.76, bw=0.189]\u001b[A\n",
            " 64%|######4   | 127/198 [01:24<00:46,  1.54it/s, epoch=1/1, loss=6.04, bw=0.18] \u001b[A\n",
            " 64%|######4   | 127/198 [01:25<00:46,  1.54it/s, epoch=1/1, loss=5.98, bw=0.225]\u001b[A\n",
            " 65%|######5   | 129/198 [01:25<00:44,  1.54it/s, epoch=1/1, loss=5.98, bw=0.225]\u001b[A\n",
            " 65%|######5   | 129/198 [01:26<00:44,  1.54it/s, epoch=1/1, loss=5.8, bw=0.216] \u001b[A\n",
            " 65%|######5   | 129/198 [01:26<00:44,  1.54it/s, epoch=1/1, loss=5.47, bw=0.378]\u001b[A\n",
            " 66%|######6   | 131/198 [01:26<00:43,  1.54it/s, epoch=1/1, loss=5.47, bw=0.378]\u001b[A\n",
            " 66%|######6   | 131/198 [01:27<00:43,  1.54it/s, epoch=1/1, loss=5.96, bw=0.207]\u001b[A\n",
            " 66%|######6   | 131/198 [01:28<00:43,  1.54it/s, epoch=1/1, loss=5.62, bw=0.207]\u001b[A\n",
            " 67%|######7   | 133/198 [01:28<00:42,  1.54it/s, epoch=1/1, loss=5.62, bw=0.207]\u001b[A\n",
            " 67%|######7   | 133/198 [01:28<00:42,  1.54it/s, epoch=1/1, loss=5.76, bw=0.135]\u001b[A\n",
            " 67%|######7   | 133/198 [01:29<00:42,  1.54it/s, epoch=1/1, loss=5.74, bw=0.162]\u001b[A\n",
            " 68%|######8   | 135/198 [01:29<00:41,  1.53it/s, epoch=1/1, loss=5.74, bw=0.162]\u001b[A\n",
            " 68%|######8   | 135/198 [01:30<00:41,  1.53it/s, epoch=1/1, loss=5.62, bw=0.198]\u001b[A\n",
            " 68%|######8   | 135/198 [01:30<00:41,  1.53it/s, epoch=1/1, loss=5.83, bw=0.216]\u001b[A\n",
            " 69%|######9   | 137/198 [01:30<00:39,  1.53it/s, epoch=1/1, loss=5.83, bw=0.216]\u001b[A\n",
            " 69%|######9   | 137/198 [01:31<00:39,  1.53it/s, epoch=1/1, loss=5.82, bw=0.207]\u001b[A\n",
            " 69%|######9   | 137/198 [01:31<00:39,  1.53it/s, epoch=1/1, loss=5.84, bw=0.108]\u001b[A\n",
            " 70%|#######   | 139/198 [01:31<00:38,  1.54it/s, epoch=1/1, loss=5.84, bw=0.108]\u001b[A\n",
            " 70%|#######   | 139/198 [01:32<00:38,  1.54it/s, epoch=1/1, loss=5.7, bw=0.207] \u001b[A\n",
            " 70%|#######   | 139/198 [01:33<00:38,  1.54it/s, epoch=1/1, loss=5.93, bw=0.18]\u001b[A\n",
            " 71%|#######1  | 141/198 [01:33<00:36,  1.54it/s, epoch=1/1, loss=5.93, bw=0.18]\u001b[A\n",
            " 71%|#######1  | 141/198 [01:33<00:36,  1.54it/s, epoch=1/1, loss=5.83, bw=0.207]\u001b[A\n",
            " 71%|#######1  | 141/198 [01:34<00:36,  1.54it/s, epoch=1/1, loss=5.87, bw=0.198]\u001b[A\n",
            " 72%|#######2  | 143/198 [01:34<00:35,  1.55it/s, epoch=1/1, loss=5.87, bw=0.198]\u001b[A\n",
            " 72%|#######2  | 143/198 [01:35<00:35,  1.55it/s, epoch=1/1, loss=5.86, bw=0.189]\u001b[A\n",
            " 72%|#######2  | 143/198 [01:35<00:35,  1.55it/s, epoch=1/1, loss=5.79, bw=0.261]\u001b[A\n",
            " 73%|#######3  | 145/198 [01:35<00:34,  1.55it/s, epoch=1/1, loss=5.79, bw=0.261]\u001b[A\n",
            " 73%|#######3  | 145/198 [01:36<00:34,  1.55it/s, epoch=1/1, loss=5.8, bw=0.171] \u001b[A\n",
            " 73%|#######3  | 145/198 [01:37<00:34,  1.55it/s, epoch=1/1, loss=5.5, bw=0.198]\u001b[A\n",
            " 74%|#######4  | 147/198 [01:37<00:33,  1.54it/s, epoch=1/1, loss=5.5, bw=0.198]\u001b[A\n",
            " 74%|#######4  | 147/198 [01:37<00:33,  1.54it/s, epoch=1/1, loss=5.56, bw=0.126]\u001b[A\n",
            " 74%|#######4  | 147/198 [01:38<00:33,  1.54it/s, epoch=1/1, loss=5.81, bw=0.162]\u001b[A\n",
            " 75%|#######5  | 149/198 [01:38<00:31,  1.53it/s, epoch=1/1, loss=5.81, bw=0.162]\u001b[A\n",
            " 75%|#######5  | 149/198 [01:39<00:31,  1.53it/s, epoch=1/1, loss=5.6, bw=0.162] \u001b[A\n",
            " 75%|#######5  | 149/198 [01:39<00:31,  1.53it/s, epoch=1/1, loss=5.66, bw=0.189]\u001b[A\n",
            " 76%|#######6  | 151/198 [01:39<00:30,  1.54it/s, epoch=1/1, loss=5.66, bw=0.189]\u001b[A\n",
            " 76%|#######6  | 151/198 [01:40<00:30,  1.54it/s, epoch=1/1, loss=5.77, bw=0.171]\u001b[A\n",
            " 76%|#######6  | 151/198 [01:41<00:30,  1.54it/s, epoch=1/1, loss=5.41, bw=0.117]\u001b[A\n",
            " 77%|#######7  | 153/198 [01:41<00:29,  1.54it/s, epoch=1/1, loss=5.41, bw=0.117]\u001b[A\n",
            " 77%|#######7  | 153/198 [01:41<00:29,  1.54it/s, epoch=1/1, loss=5.35, bw=0.126]\u001b[A\n",
            " 77%|#######7  | 153/198 [01:42<00:29,  1.54it/s, epoch=1/1, loss=5.52, bw=0.135]\u001b[A\n",
            " 78%|#######8  | 155/198 [01:42<00:27,  1.54it/s, epoch=1/1, loss=5.52, bw=0.135]\u001b[A\n",
            " 78%|#######8  | 155/198 [01:43<00:27,  1.54it/s, epoch=1/1, loss=5.33, bw=0.162]\u001b[A\n",
            " 78%|#######8  | 155/198 [01:43<00:27,  1.54it/s, epoch=1/1, loss=5.49, bw=0.162]\u001b[A\n",
            " 79%|#######9  | 157/198 [01:43<00:26,  1.54it/s, epoch=1/1, loss=5.49, bw=0.162]\u001b[A\n",
            " 79%|#######9  | 157/198 [01:44<00:26,  1.54it/s, epoch=1/1, loss=5.73, bw=0.171]\u001b[A\n",
            " 79%|#######9  | 157/198 [01:44<00:26,  1.54it/s, epoch=1/1, loss=5.5, bw=0.207] \u001b[A\n",
            " 80%|########  | 159/198 [01:44<00:25,  1.54it/s, epoch=1/1, loss=5.5, bw=0.207]\u001b[A\n",
            " 80%|########  | 159/198 [01:45<00:25,  1.54it/s, epoch=1/1, loss=5.5, bw=0.126]\u001b[A\n",
            " 80%|########  | 159/198 [01:46<00:25,  1.54it/s, epoch=1/1, loss=5.5, bw=0.171]\u001b[A\n",
            " 81%|########1 | 161/198 [01:46<00:23,  1.54it/s, epoch=1/1, loss=5.5, bw=0.171]\u001b[A\n",
            " 81%|########1 | 161/198 [01:46<00:23,  1.54it/s, epoch=1/1, loss=5.84, bw=0.153]\u001b[A\n",
            " 81%|########1 | 161/198 [01:47<00:23,  1.54it/s, epoch=1/1, loss=5.3, bw=0.117] \u001b[A\n",
            " 82%|########2 | 163/198 [01:47<00:22,  1.54it/s, epoch=1/1, loss=5.3, bw=0.117]\u001b[A\n",
            " 82%|########2 | 163/198 [01:48<00:22,  1.54it/s, epoch=1/1, loss=5.37, bw=0.189]\u001b[A\n",
            " 82%|########2 | 163/198 [01:48<00:22,  1.54it/s, epoch=1/1, loss=5.54, bw=0.144]\u001b[A\n",
            " 83%|########3 | 165/198 [01:48<00:21,  1.53it/s, epoch=1/1, loss=5.54, bw=0.144]\u001b[A\n",
            " 83%|########3 | 165/198 [01:49<00:21,  1.53it/s, epoch=1/1, loss=5.73, bw=0.117]\u001b[A\n",
            " 83%|########3 | 165/198 [01:50<00:21,  1.53it/s, epoch=1/1, loss=5.52, bw=0.189]\u001b[A\n",
            " 84%|########4 | 167/198 [01:50<00:20,  1.54it/s, epoch=1/1, loss=5.52, bw=0.189]\u001b[A\n",
            " 84%|########4 | 167/198 [01:50<00:20,  1.54it/s, epoch=1/1, loss=6.13, bw=0.126]\u001b[A\n",
            " 84%|########4 | 167/198 [01:51<00:20,  1.54it/s, epoch=1/1, loss=5.28, bw=0.0991]\u001b[A\n",
            " 85%|########5 | 169/198 [01:51<00:18,  1.55it/s, epoch=1/1, loss=5.28, bw=0.0991]\u001b[A\n",
            " 85%|########5 | 169/198 [01:52<00:18,  1.55it/s, epoch=1/1, loss=5.8, bw=0.126]  \u001b[A\n",
            " 85%|########5 | 169/198 [01:52<00:18,  1.55it/s, epoch=1/1, loss=5.85, bw=0.126]\u001b[A\n",
            " 86%|########6 | 171/198 [01:52<00:17,  1.54it/s, epoch=1/1, loss=5.85, bw=0.126]\u001b[A\n",
            " 86%|########6 | 171/198 [01:53<00:17,  1.54it/s, epoch=1/1, loss=5.42, bw=0.117]\u001b[A\n",
            " 86%|########6 | 171/198 [01:54<00:17,  1.54it/s, epoch=1/1, loss=5.26, bw=0.0901]\u001b[A\n",
            " 87%|########7 | 173/198 [01:54<00:16,  1.54it/s, epoch=1/1, loss=5.26, bw=0.0901]\u001b[A\n",
            " 87%|########7 | 173/198 [01:54<00:16,  1.54it/s, epoch=1/1, loss=5.94, bw=0.108] \u001b[A\n",
            " 87%|########7 | 173/198 [01:55<00:16,  1.54it/s, epoch=1/1, loss=5.55, bw=0.0901]\u001b[A\n",
            " 88%|########8 | 175/198 [01:55<00:14,  1.54it/s, epoch=1/1, loss=5.55, bw=0.0901]\u001b[A\n",
            " 88%|########8 | 175/198 [01:55<00:14,  1.54it/s, epoch=1/1, loss=5.22, bw=0.171] \u001b[A\n",
            " 88%|########8 | 175/198 [01:56<00:14,  1.54it/s, epoch=1/1, loss=5.76, bw=0.117]\u001b[A\n",
            " 89%|########9 | 177/198 [01:56<00:13,  1.54it/s, epoch=1/1, loss=5.76, bw=0.117]\u001b[A\n",
            " 89%|########9 | 177/198 [01:57<00:13,  1.54it/s, epoch=1/1, loss=5.38, bw=0.162]\u001b[A\n",
            " 89%|########9 | 177/198 [01:57<00:13,  1.54it/s, epoch=1/1, loss=5.69, bw=0.0901]\u001b[A\n",
            " 90%|######### | 179/198 [01:57<00:12,  1.54it/s, epoch=1/1, loss=5.69, bw=0.0901]\u001b[A\n",
            " 90%|######### | 179/198 [01:58<00:12,  1.54it/s, epoch=1/1, loss=5.84, bw=0.171] \u001b[A\n",
            " 90%|######### | 179/198 [01:59<00:12,  1.54it/s, epoch=1/1, loss=5.54, bw=0.0991]\u001b[A\n",
            " 91%|#########1| 181/198 [01:59<00:11,  1.53it/s, epoch=1/1, loss=5.54, bw=0.0991]\u001b[A\n",
            " 91%|#########1| 181/198 [01:59<00:11,  1.53it/s, epoch=1/1, loss=5.62, bw=0.117] \u001b[A\n",
            " 91%|#########1| 181/198 [02:00<00:11,  1.53it/s, epoch=1/1, loss=5.93, bw=0.0991]\u001b[A\n",
            " 92%|#########2| 183/198 [02:00<00:09,  1.53it/s, epoch=1/1, loss=5.93, bw=0.0991]\u001b[A\n",
            " 92%|#########2| 183/198 [02:01<00:09,  1.53it/s, epoch=1/1, loss=5.49, bw=0.144] \u001b[A\n",
            " 92%|#########2| 183/198 [02:01<00:09,  1.53it/s, epoch=1/1, loss=5.09, bw=0.0631]\u001b[A\n",
            " 93%|#########3| 185/198 [02:01<00:08,  1.54it/s, epoch=1/1, loss=5.09, bw=0.0631]\u001b[A\n",
            " 93%|#########3| 185/198 [02:02<00:08,  1.54it/s, epoch=1/1, loss=5.43, bw=0.0811]\u001b[A\n",
            " 93%|#########3| 185/198 [02:03<00:08,  1.54it/s, epoch=1/1, loss=5.66, bw=0.135] \u001b[A\n",
            " 94%|#########4| 187/198 [02:03<00:07,  1.54it/s, epoch=1/1, loss=5.66, bw=0.135]\u001b[A\n",
            " 94%|#########4| 187/198 [02:03<00:07,  1.54it/s, epoch=1/1, loss=5.64, bw=0.108]\u001b[A\n",
            " 94%|#########4| 187/198 [02:04<00:07,  1.54it/s, epoch=1/1, loss=5.35, bw=0.036]\u001b[A\n",
            " 95%|#########5| 189/198 [02:04<00:05,  1.54it/s, epoch=1/1, loss=5.35, bw=0.036]\u001b[A\n",
            " 95%|#########5| 189/198 [02:05<00:05,  1.54it/s, epoch=1/1, loss=5.81, bw=0.135]\u001b[A\n",
            " 95%|#########5| 189/198 [02:05<00:05,  1.54it/s, epoch=1/1, loss=5.69, bw=0.108]\u001b[A\n",
            " 96%|#########6| 191/198 [02:05<00:04,  1.53it/s, epoch=1/1, loss=5.69, bw=0.108]\u001b[A\n",
            " 96%|#########6| 191/198 [02:06<00:04,  1.53it/s, epoch=1/1, loss=5.52, bw=0.144]\u001b[A\n",
            " 96%|#########6| 191/198 [02:07<00:04,  1.53it/s, epoch=1/1, loss=5.23, bw=0.135]\u001b[A\n",
            " 97%|#########7| 193/198 [02:07<00:03,  1.53it/s, epoch=1/1, loss=5.23, bw=0.135]\u001b[A\n",
            " 97%|#########7| 193/198 [02:07<00:03,  1.53it/s, epoch=1/1, loss=5.63, bw=0.108]\u001b[A\n",
            " 97%|#########7| 193/198 [02:08<00:03,  1.53it/s, epoch=1/1, loss=5.37, bw=0.117]\u001b[A\n",
            " 98%|#########8| 195/198 [02:08<00:01,  1.52it/s, epoch=1/1, loss=5.37, bw=0.117]\u001b[A\n",
            " 98%|#########8| 195/198 [02:09<00:01,  1.52it/s, epoch=1/1, loss=5.44, bw=0.0901]\u001b[A\n",
            " 98%|#########8| 195/198 [02:09<00:01,  1.52it/s, epoch=1/1, loss=5.44, bw=0.045] \u001b[A\n",
            " 99%|#########9| 197/198 [02:09<00:00,  1.52it/s, epoch=1/1, loss=5.44, bw=0.045]\u001b[A\n",
            " 99%|#########9| 197/198 [02:10<00:00,  1.52it/s, epoch=2/1, loss=5.42, bw=0.0721]\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "[2m 10s (2 198 100%) loss=5.4151 bw=0.0821]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "Litwo! Ojczyzno moja! \n",
              "<br/>Sa<font color=\"red\">++</font> pierś Wszyne słumy <font color=\"red\">--</font>wniawada<font color=\"red\">++</font>: Przerokiem. \n",
              "<br/>\n",
              "<br/>Bo czękufa<font color=\"red\">++</font>, ta<font color=\"red\">++</font> załorą, i do i rata, \n",
              "<br/>A poracy Wieść Sęrza Pan A owiddzenie, \n",
              "<br/>Krzywet nacież z Słylszcze do to wilła; \n",
              "<br/>W niega<font color=\"red\">++</font> wiel<font color=\"red\">++</font> się Dłu<font color=\"red\">++</font> do ubin brał jedzi, \n",
              "<br/>To <font color=\"red\">--</font>deusz narium <font color=\"red\">--</font>na przele i obna powne <font color=\"red\">--</font>sem, \n",
              "<br/>Tylcy się Nią jak krowrót kom<font color=\"red\">++</font> grzeby i za <font color=\"red\">--</font>zem, \n",
              "<br/>\n",
              "<br/>Hrało Wyko<font color=\"red\">++</font> wygo, paży widzi ugali: \n",
              "<br/>Ich Ta<font color=\"red\">++</font> kana. \n",
              "<br/>\n",
              "<br/>Oblizał ołym, pan, wszys<font color=\"red\">++</font> do z że zwiedzi. \n",
              "<br/>Znoną Trze<font color=\"red\">++</font> Wojna <font color=\"red\">--</font>ne<font color=\"red\">++</font> drob<font color=\"red\">++</font> omia<font color=\"red\">++</font>: \n",
              "<br/>A I w pokuło piedogo wpadgim, \n",
              "<br/>Słudu, podgaszna za<font color=\"red\">++</font> ją Bezli gającę. \n",
              "<br/>Ale <font color=\"red\">--</font> Ja Spadtwym co<font color=\"red\">++</font>, palmiany na <font color=\"red\">--</font>ćka <font color=\"red\">--</font>jem<font color=\"red\">++</font>. \n",
              "<br/>\n",
              "<br/>Roz<font color=\"red\">++</font> praw się \n",
              "<br/>Odczamo<font color=\"red\">++</font>, pęmożków, po<font color=\"red\">++</font> znę<font color=\"red\">++</font> biaże, \n",
              "<br/>Zokoła, hrajłem ragień radzi; Pa<font color=\"red\">++</font>! \n",
              "<br/>Porzniem na dość <font color=\"red\">--</font>ło stobia zamek powanie, \n",
              "<br/>Sęgał mu wydydził <font color=\"red\">--</font>ło o zmy<font color=\"red\">++</font> o durawy. \n",
              "<br/>\n",
              "<br/>I Nielesza Pawie, znikdym, hralinach \n",
              "<br/>Wiel<font color=\"red\">++</font> zboki się krobu<font color=\"red\">++</font>, czas, wyweło. \n",
              "<br/>Za Są częku się My Zacy, dasana Odwarli \n",
              "<br/>Poczę Hrawako na nim zbyt poreno w enina, \n",
              "<br/>Po re<font color=\"red\">++</font> Posłszy przedzi bobieliła w mnó<font color=\"red\">++</font> \n",
              "<br/>Słulimi czypali, padziano, \n",
              "<br/>Je pan Ja gorzéj <font color=\"red\">--</font>ża, zwano <font color=\"red\">--</font> Choć Nakój to ręwie, \n",
              "<br/>Koki ca<font color=\"red\">++</font> rę<font color=\"red\">++</font>, pała, czu<font color=\"red\">++</font> ale Teny. \n",
              "<br/>\n",
              "<br/>Nano tak Bydzi i tak ładzi, uleną \n",
              "<br/>To To Ni<font color=\"red\">++</font> W wyrago za<font color=\"red\">++</font> pierś? podkę. \n",
              "<br/>« Tu to <font color=\"red\">--</font>raz Jąd<font color=\"red\">++</font> Wykąż <font color=\"red\">--</font>milgo Czło<font color=\"red\">++</font> w hraca stro<font color=\"red\">++</font>, \n",
              "<br/>Wielina za<font color=\"red\">++</font> końłem poni, miestagda, \n",
              "<br/>Oją Sędzia, w Asza, powet wparnąć jak po kul <font color=\"red\">--</font>czył. \n",
              "<br/>Olirano to koca wyki stobie<font color=\"red\">++</font>, \n",
              "<br/>I Przylibiena w ugo kratałem, \n",
              "<br/>Asma<font color=\"red\">++</font>: porę<font color=\"red\">++</font>, gękien Nad owiegu, \n",
              "<br/>I To Spał <font color=\"red\">--</font>liując ręs<font color=\"red\">++</font>, z pokrut zedana. \n",
              "<br/>Przy <font color=\"red\">--</font>stce On tyjąc jeźną na lecz sarborzęle \n",
              "<br/>Hraścine<font color=\"red\">++</font> rusza, chojach poniec zadzież, \n",
              "<br/>Nie Pan Nobiła paleła, to z <font color=\"red\">--</font>Tro Wojnych. \n",
              "<br/>On tymdzia Bo nie <font color=\"red\">--</font> Nad W na zdadek, dłulirza, \n",
              "<br/>Wojra, jak tak Nad i strzedała, z Rowiódł <font color=\"red\">--</font>bra, \n",
              "<br/>Źle, choć Gdy Donów zastrze<font color=\"red\">++</font> złemał tak wypawa<font color=\"red\">++</font>. \n",
              "<br/>Ole zajedła Zdu<font color=\"red\">++</font> z niełóty <font color=\"red\">--</font>ła, \n",
              "<br/>Ocholije odziéć, kto naglągo Téj Wyje<font color=\"red\">++</font>, \n",
              "<br/>\n",
              "<br/>na teli<font color=\"red\">++</font> strona izki, doraczył, \n",
              "<br/>Wydziejąc ośli<font color=\"red\">++</font> się Sony i co Proków \n",
              "<br/>Proraz, pije Podłych? jak ucy Gdzie doki, \n",
              "<br/>Sam Gdy Pan To Ja nie przewąd żyła; \n",
              "<br/>Sębia Ta<font color=\"red\">++</font> Duwo A była wieldzy i paca \n",
              "<br/>Oko Że Nieliligo I Dob<font color=\"red\">++</font> kie<font color=\"red\">++</font>, od w to gnieczany, \n",
              "<br/>I fidci, o tatb<font color=\"red\">++</font> młocy nie przyni \n",
              "<br/>Uma, lub prana zeła się się wy<font color=\"red\">++</font> dwojwoje. \n",
              "<br/>A I stasto, wiel<font color=\"red\">++</font> w w <font color=\"red\">--</font>dzia Aż przydziłam czana \n",
              "<br/>Dwóch Ale widać, bynie nadział, panciła, \n",
              "<br/>W uwrózwoi<font color=\"red\">++</font>? Do? Wieje, przemamy, \n",
              "<br/>Wsparł Się Stryj <font color=\"red\">--</font>ce kona, te<font color=\"red\">++</font> wy<font color=\"red\">++</font> w dłumoje, \n",
              "<br/>Przy Na Pochem, Wyli, uwie<font color=\"red\">++</font> z się zadrózuje. \n",
              "<br/>\n",
              "<br/>Zanoga, poprzód, i <font color=\"red\">--</font>ki Poło to"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "100%|##########| 198/198 [02:11<00:00,  1.03it/s, epoch=2/1, loss=5.42, bw=0.0721]\u001b[A\n",
            "                                                                                  \u001b[A"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dXrPD94SXM5m"
      },
      "source": [
        "### Kreślenie wartości straty\n",
        "\n",
        "Wykreślanie historii straty z `all_losses` pokazuje uczenie sieci:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "meKCxPo3XM5n",
        "outputId": "275ead7d-ed37-4b0c-a6cd-6c099c5820aa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 442
        }
      },
      "source": [
        "plt.figure()\n",
        "plt.plot(all_losses)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x7fe1f8b06128>]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 60
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WabkwPqZ5WlH"
      },
      "source": [
        "### Zapis i odczyt sieci"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EtK-9BuuB-GX"
      },
      "source": [
        "#### Zapisanie sieci"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aSA3Utpc6dXV",
        "outputId": "b86c73b3-dc21-4a94-b706-7c67c9c52bd2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# n_epochs=15\n",
        "\n",
        "ALLTOKS, MODEL = ['all_tokens', 'model']\n",
        "fn_pan_tadeusz = {ALLTOKS: f'all_tokens.n{n_tokens}.pan_tadeusz.p', \n",
        "                  MODEL: f'pan_tadeusz.h{hidden_size}.l{n_layers}.e{n_epochs}.gpu.torch'}\n",
        "fn_dict = fn_pan_tadeusz; fn_dict"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'all_tokens': 'all_tokens.n5059.pan_tadeusz.p',\n",
              " 'model': 'pan_tadeusz.h500.l3.e1.gpu.torch'}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 61
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XJ-j5_4I6d0g"
      },
      "source": [
        "# save all_tokens\n",
        "all_tokens_path = tmp_path / fn_dict[ALLTOKS]\n",
        "pickle.dump(all_tokens, open(all_tokens_path, 'wb'))\n",
        "\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# save model\n",
        "model_path = tmp_path / fn_dict[MODEL]\n",
        "torch.save(decoder, model_path)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dt8_7GshWi4M",
        "outputId": "e099516c-f431-419b-e533-4454852e2544",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "ls -lah $tmp_path"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "total 106M\n",
            "drwxr-xr-x 2 root root 4.0K Nov 14 12:02 \u001b[0m\u001b[01;34m.\u001b[0m/\n",
            "drwxr-xr-x 3 root root 4.0K Nov 14 11:55 \u001b[01;34m..\u001b[0m/\n",
            "-rw-r--r-- 1 root root  63K Nov 14 11:53 all_tokens.n4064.witkacy_szewcy.p\n",
            "-rw-r--r-- 1 root root  80K Nov 14 12:02 all_tokens.n5059.pan_tadeusz.p\n",
            "-rw-r--r-- 1 root root 5.2K Nov 14 12:01 e_syl.txt\n",
            "-rw-r--r-- 1 root root  37M Nov 14 12:02 pan_tadeusz.h500.l3.e1.gpu.torch\n",
            "-rw-r--r-- 1 root root  37M Nov 14 11:53 pan_tadeusz.h500.l3.e20.gpu.torch\n",
            "-rw-r--r-- 1 root root   35 Nov 14 11:59 tmp_text_caps1.txt\n",
            "-rw-r--r-- 1 root root   56 Nov 14 11:59 tmp_text_syl1.txt\n",
            "-rw-r--r-- 1 root root  33M Nov 14 11:53 witkacy_szewcy.h500.l3.e11.gpu.torch\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qHbGgVULB_cp",
        "outputId": "456852fa-7529-4bbb-f7b1-d8023e5f1553",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "decoder.state_dict"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<bound method Module.state_dict of RNN(\n",
              "  (encoder): Embedding(5059, 500)\n",
              "  (gru): GRU(500, 500, num_layers=3)\n",
              "  (decoder): Linear(in_features=500, out_features=5059, bias=True)\n",
              ")>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 64
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BalhBXFKfErp"
      },
      "source": [
        "#### Załadowanie sieci"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hk7EWQXmgfdB",
        "outputId": "9e6b8312-8ee4-4ceb-8eb9-d07aa0ec7d40",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "ls -lah $tmp_path"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "total 106M\n",
            "drwxr-xr-x 2 root root 4.0K Nov 14 12:02 \u001b[0m\u001b[01;34m.\u001b[0m/\n",
            "drwxr-xr-x 3 root root 4.0K Nov 14 11:55 \u001b[01;34m..\u001b[0m/\n",
            "-rw-r--r-- 1 root root  63K Nov 14 11:53 all_tokens.n4064.witkacy_szewcy.p\n",
            "-rw-r--r-- 1 root root  80K Nov 14 12:02 all_tokens.n5059.pan_tadeusz.p\n",
            "-rw-r--r-- 1 root root 5.2K Nov 14 12:01 e_syl.txt\n",
            "-rw-r--r-- 1 root root  37M Nov 14 12:02 pan_tadeusz.h500.l3.e1.gpu.torch\n",
            "-rw-r--r-- 1 root root  37M Nov 14 11:53 pan_tadeusz.h500.l3.e20.gpu.torch\n",
            "-rw-r--r-- 1 root root   35 Nov 14 11:59 tmp_text_caps1.txt\n",
            "-rw-r--r-- 1 root root   56 Nov 14 11:59 tmp_text_syl1.txt\n",
            "-rw-r--r-- 1 root root  33M Nov 14 11:53 witkacy_szewcy.h500.l3.e11.gpu.torch\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "67lBaaQ1gg3B",
        "outputId": "8c694a4c-418e-49d3-ff3d-74edbbe41bd3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "n_epochs=20\n",
        "ALLTOKS, MODEL = ['all_tokens', 'model']\n",
        "fn_pan_tadeusz = {ALLTOKS: f'all_tokens.n{n_tokens}.pan_tadeusz.p', \n",
        "                  MODEL: f'pan_tadeusz.h{hidden_size}.l{n_layers}.e{n_epochs}.gpu.torch'}\n",
        "fn_dict = fn_pan_tadeusz; fn_dict"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'all_tokens': 'all_tokens.n5059.pan_tadeusz.p',\n",
              " 'model': 'pan_tadeusz.h500.l3.e1.gpu.torch'}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 68
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-D9_ONXNMHPK",
        "outputId": "06d40d90-00b4-4121-d8f3-dd6d6b2838b2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "if True:\n",
        "  all_tokens_path = tmp_path / fn_dict[ALLTOKS]\n",
        "  print(f'all_tokens_path = {all_tokens_path}')\n",
        "  all_tokens = pickle.load(open(all_tokens_path, 'rb'))\n",
        "  n_characters = len(all_tokens)\n",
        "  tok2idx_dict = {tok: idx for (idx, tok) in enumerate(all_tokens)}\n",
        "\n",
        "  model_path = tmp_path / fn_dict[MODEL]\n",
        "  decoder = torch.load(model_path)\n",
        "  decoder.gru.flatten_parameters()\n",
        "  print(f'model_path = {model_path}')\n",
        "  print(decoder.state_dict)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "all_tokens_path = data/rnn_generator/tmp/all_tokens.n5059.pan_tadeusz.p\n",
            "model_path = data/rnn_generator/tmp/pan_tadeusz.h500.l3.e1.gpu.torch\n",
            "<bound method Module.state_dict of RNN(\n",
            "  (encoder): Embedding(5059, 500)\n",
            "  (gru): GRU(500, 500, num_layers=3)\n",
            "  (decoder): Linear(in_features=500, out_features=5059, bias=True)\n",
            ")>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2fEFWi-FXM5p"
      },
      "source": [
        "## Ewaluacja w różnych \"temperaturach\"\n",
        "\n",
        "W powyższej funkcji `evaluate`, za każdym razem, gdy dokonywana jest prognoza, wyjścia są dzielone przez przekazany argument \"temperature\". Użycie większej liczby sprawia, że wszystkie akcje są bardziej jednakowo prawdopodobne, a tym samym dają nam \"bardziej losowe\" wyniki. Użycie mniejszej wartości (mniejszej niż 1) sprawia, że wysokie prawdopodobieństwa przyczyniają się bardziej. Gdy ustawiamy temperaturę na zero, wybieramy tylko najbardziej prawdopodobne wyjścia.\n",
        "\n",
        "Możemy zobaczyć te efekty poprzez dostosowanie argumentu `temperature`.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zbRXU5j1LR3_"
      },
      "source": [
        "def print_eval(e_syl):\n",
        "  display(HTML(format_html(fix_punctuation(decode_tokens(syl2str(e_syl, delim=''))))))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E4MTNidlS6j2"
      },
      "source": [
        "prime_tok = str2syl2tok('Litwo! Ojczyzno moja!')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gBm5ibSnXM5p",
        "outputId": "ae89136f-eb22-4685-c820-a95ddfc68689",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 255
        }
      },
      "source": [
        "print_eval(evaluate(prime_tok, 200, temperature=0.8))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "Litwo! Ojczyzno moja! \n",
              "<br/>Słosto <font color=\"red\">--</font>ra A Mnie <font color=\"red\">--</font>cu, przesi! Niego po dach? \n",
              "<br/>Caraz w czała; Końpe<font color=\"red\">++</font>, uwtrzył Znokoży<font color=\"red\">++</font>. \n",
              "<br/>Przeców słu<font color=\"red\">++</font> i \n",
              "<br/>Racha, ta<font color=\"red\">++</font> ręwaciw<font color=\"red\">++</font> w ciłota. \n",
              "<br/>Tych Z I na<font color=\"red\">++</font> pene rokoli i tryumcania, \n",
              "<br/>Aż Słońmele<font color=\"red\">++</font>, to jest Tesza Zmieni \n",
              "<br/>Wiczana rozdział; nim wrógun<font color=\"red\">++</font> sła<font color=\"red\">++</font> i jest miena: \n",
              "<br/>Gorna gocy, duliprzód, téj jak na czenie: \n",
              "<br/>Drulowameniem nie bostrza<font color=\"red\">++</font> tę, \n",
              "<br/>To gogo bo Obło wy<font color=\"red\">++</font> mak, skrzydmi nie<font color=\"red\">++</font> mor<font color=\"red\">++</font>! \n",
              "<br/>I że Posmi w i Te<font color=\"red\">++</font> I na in<font color=\"red\">++</font> droka \n",
              "<br/>Ale Salilisu Za drostwa, z <font color=\"red\">--</font>Deusz <font color=\"red\">--</font>cy, \n",
              "<br/>Woj<font color=\"red\">++</font> W"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DnStt-FzXM5r"
      },
      "source": [
        "Niższe temperatury daja mniejszą różnorodność, wybierając tylko bardziej prawdopodobne wyjścia:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D3mkq_sCXM5r",
        "outputId": "1e0425fd-1816-4a2f-f646-0752f5be87da",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        }
      },
      "source": [
        "print_eval(evaluate(prime_tok, 200, temperature=0.2))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "Litwo! Ojczyzno moja! \n",
              "<br/>I Oliła, polena, w To Telili, \n",
              "<br/>I Pan I I I Polina, Pan I Telina, \n",
              "<br/>I I Teligo w To Ta<font color=\"red\">++</font> Hra<font color=\"red\">++</font> W Teligo, \n",
              "<br/>I Ta<font color=\"red\">++</font> Hra<font color=\"red\">++</font> I Ta<font color=\"red\">++</font> Teliła, \n",
              "<br/>I Teligo, Pan I Ta<font color=\"red\">++</font> Hralimonie, \n",
              "<br/>I Ta<font color=\"red\">++</font> Teliła, w Teliła, i I I Hralina \n",
              "<br/>I Wyraz, i Olina, i I Ta<font color=\"red\">++</font> Hralina \n",
              "<br/>I I Teliła Nalina, i Pan I Pan I Hraty, \n",
              "<br/>I Te<font color=\"red\">++</font> Polino, i W Ta<font color=\"red\">++</font> Ta<font color=\"red\">++</font> Telili,"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l508QP1LXM5t"
      },
      "source": [
        "Wyższe temperatury są bardziej różnorodne, wybierając mniej prawdopodobne wyjścia:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SxhfgI-PXM5u",
        "outputId": "1fcd36de-de2c-4af4-9911-9399aac80cd0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        }
      },
      "source": [
        "print_eval(evaluate(prime_tok, 200, temperature=1.4))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "Litwo! Ojczyzno moja! \n",
              "<br/><font color=\"red\">--</font>Deucza częre z <font color=\"red\">--</font>sze <font color=\"red\">--</font>ną <font color=\"red\">--</font>dzy <font color=\"red\">--</font>wny <font color=\"red\">--</font>ściem błynia <font color=\"red\">--</font>cussłuzeysbach <font color=\"red\">--</font>dzi \n",
              "<br/>Nas stem<font color=\"red\">++</font> klas<font color=\"red\">++</font> wielku<font color=\"red\">++</font> sietewstwa za<font color=\"red\">++</font> chcąc sworase<font color=\"red\">++</font>. \n",
              "<br/>wie<font color=\"red\">++</font> los syt ziemba<font color=\"red\">++</font> ślad <font color=\"red\">--</font>leostobyt<font color=\"red\">++</font> ecy. os brzebodzi: się w kwapadł; końlali. \n",
              "<br/>Ole za <font color=\"red\">--</font>pomwić zwitarum <font color=\"red\">--</font>zy już tj. \n",
              "<br/><font color=\"red\">--</font>Pitéj szarę<font color=\"red\">++</font>, <font color=\"red\">--</font>bum rowinych za pod szotwo zdołem <font color=\"red\">--</font>skim <font color=\"red\">--</font>ru \n",
              "<br/>Wiebę nie <font color=\"red\">--</font>szem <font color=\"red\">--</font>libo zdace, złołem tre<font color=\"red\">++</font> Jali. \n",
              "<br/>Posią góda się <font color=\"red\">--</font>warstrzęś<font color=\"red\">++</font> z; niżwość <font color=\"red\">--</font>chcąc <font color=\"red\">--</font>byżył <font color=\"red\">--</font>deudnie. \n",
              "<br/>w to lub <font color=\"red\">--</font>nierzkie sto <font color=\"red\">--</font>jrzał roznące dach: siwéj nie <font color=\"red\">--</font>Wan<font color=\"red\">++</font> niéj <font color=\"red\">--</font>ńczo<font color=\"red\">++</font> końsze i \n",
              "<br/>A <font color=\"red\">--</font>kiem tych strzelb wygaki_ <font color=\"red\">--</font>tyc<font color=\"red\">++</font> do sterniem ła<font color=\"red\">++</font> gdzie, \n",
              "<br/>Rocię groźkę os<font color=\"red\">++</font> barniach już wawdząc <font color=\"red\">--</font>ka ku <font color=\"red\">--</font>żył że swa<font color=\"red\">++</font>. \n",
              "<br/>\n",
              "<br/>Sień zwłasach <font color=\"red\">--</font>ctwem <font color=\"red\">--</font>sta<font color=\"red\">++</font> wiodł <font color=\"red\">--</font>szę zieszło le<font color=\"red\">++</font>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-UQoZYk2XM5v"
      },
      "source": [
        "## Ćwiczenia\n",
        "\n",
        "* Trenuj z własnym zestawem danych, np.\n",
        "     * Tekst od innego autora\n",
        "     * Posty na blogu\n",
        "     * Kody źródłowe\n",
        "* Zwiększ liczbę warstw i rozmiar sieci, aby uzyskać lepsze wyniki"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pFHHvkI6XM5w"
      },
      "source": [
        "**Następnie**: [Generating Names with a Conditional Character-Level RNN](https://github.com/spro/practical-pytorch/blob/master/conditional-char-rnn/conditional-char-rnn.ipynb)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2tJDT2lCceZL"
      },
      "source": [
        "## (debug) Monitorowanie maszyny wirtualnej"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bKdCiolHcg4e"
      },
      "source": [
        "def print_memsize():\n",
        "  process = psutil.Process(os.getpid())\n",
        "  print(f'{process.memory_info().rss / 1024**3:.5} GB')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "diBUUyOociRy",
        "outputId": "00aa5912-9fdb-49a2-dffd-75ec70d71c0b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "print_memsize()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2.751 GB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TuHoo0ARtjz_",
        "outputId": "15704364-052c-4690-fdea-d2cb3c35408d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "!uptime"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " 12:12:31 up 37 min,  0 users,  load average: 0.07, 0.09, 0.17\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f-NsNCAaq89c"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}